{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04430b0f",
   "metadata": {},
   "source": [
    "# Which Asset Classes Give a Swiss Investor a Good Hedge Against Inflation?\n",
    "\n",
    "### Authors:\n",
    "- **Laila Hassan** (194-29-174)\n",
    "- **Milena Zanolari** (16-722-076)  \n",
    "- **Izidor Erazem Kamšek** (24-719-478)  \n",
    "- **Benjamin Helmy** (17-121-732) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac40a2d",
   "metadata": {},
   "source": [
    "This study investigates the inflation-hedging potential of various asset classes for Swiss investors, focusing on the ability of stocks, fixed income, real estate, commodities, and cryptocurrencies to preserve purchasing power during inflationary periods. By applying three analytical methodologies—single-beta linear regression, correlation analysis, and real return analysis—we evaluate the effectiveness of these asset classes over different time horizons (short-term, medium-term, and long-term). Key findings suggest that real estate consistently provides strong protection against long-term inflation, while commodities offer short- to medium-term benefits. Fixed income securities, especially inflation-linked bonds, show moderate effectiveness, and cryptocurrencies, despite their high real returns, exhibit high volatility and limited reliability as inflation hedges. The study concludes that a diversified portfolio incorporating commodities, real estate, and fixed income assets is optimal for hedging against inflation, particularly for Swiss investors, while highlighting the importance of using regression analysis for more reliable and intuitive results. The limitations of the study include computational constraints and the reliance on historical data, suggesting future research into alternative modeling techniques and the consideration of macroeconomic factors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa478f7",
   "metadata": {},
   "source": [
    "### Structure:\n",
    "1. Introduction \n",
    "- Motivation\n",
    "- Background\n",
    "- Context and Literature Review\n",
    "- Asset Classes\n",
    "- Data\n",
    "2. Calculation Methods\n",
    "- Single-Beta Linear Regression\n",
    "- Correlation Analysis\n",
    "- Real Return Analysis\n",
    "3. Methodology\n",
    "- Evaluation of Frameworks\n",
    "- Robustness Check\n",
    "4. Calculation, interpretation and visualisation (same for all three calculation methods)\n",
    "- Portfolio Creation\n",
    "- Beta Calculation and Max/Min Correlation Tables\n",
    "- Visualization\n",
    "5. Comparison and Interpretation of Results\n",
    "6. Conclusion and Further Research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939e4c80",
   "metadata": {},
   "source": [
    "## 1. Introduction \n",
    "### 1.1. Motivation\n",
    "\n",
    "Inflation erodes the purchasing power of money, posing a significant challenge for investors seeking to preserve and grow their wealth. For Swiss investors, this challenge is particularly complex due to Switzerland’s historically low inflation rates and the strength and stability of the currency, which distinguish it from global markets. However, the current global economic environment — shaped by the recent COVID-19 pandemic, rising inflation, and heightened uncertainty — has raised concerns about the ability of traditional investment strategies to sustain real returns. As a result, identifying asset classes and constructing portfolios that potentially protect against inflation has become of significant importance for preserving wealth and achieving financial objectives. This study focuses on Swiss investors and therefore Swiss inflation to provide relevant insights into how portfolios of different asset classes, including stocks, commodities, fixed income, real estate, and cryptocurrencies, perform as hedging tools during inflationary periods. By analyzing multiple time frames, this study aims to give insights in building inflation-resilient portfolios and selecting specific securities within each asset class that offer superior protection against inflationary pressures.\n",
    "\n",
    "### 1.2. Background\n",
    "According to Parkin (2015), inflation is \"a process of continuously rising prices, or equivalently, a continuously falling value of money.\" The Consumer Price Index (CPI) is commonly used as a proxy for inflation, as it captures consumer price growth and provides a stable indicator of inflation trends. Despite its limitations (e.g., data timing lags, international discrepancies), CPI remains the standard for analyzing inflation.\n",
    "In the context of inflation, hedging refers to an asset’s ability to maintain or increase its real value relative to inflation. A strong inflation hedge shows a positive correlation between the asset’s returns and inflation (Fama & Schwert, 1977). Ideally, a \"perfect hedge\" would have a correlation of 1, fully offsetting increases in the price level. However, the goal is to identify assets that meaningfully co-move with inflation, protecting against eroding purchasing power (Bodie, 1976).\n",
    "\n",
    "This study applies correlation, real return analysis and linear regression to identify asset classes and portfolios that positively correlate with inflation, offering real protection for Swiss investors without heavy reliance on leverage or complex strategies.\n",
    "\n",
    "\n",
    "### 1.3. Context and Literature Review\n",
    "In their comprehensive review, *What Do Scientists Know About Inflation Hedging?*, Stephan Arnold and Benjamin R. Auer (2015) \\cite{arnold2015inflation} synthesize empirical evidence on the inflation-hedging effectiveness of stocks, gold, fixed-income securities, and real estate. Their findings reveal mixed results across asset classes, highlighting that no single asset class consistently provides effective inflation protection. Additionally, their review emphasizes the need for a comprehensive analysis of multiple asset classes in a single framework to enable direct comparisons and offer actionable insights for specific investor groups.\n",
    "Building on their work, this paper seeks to fill that gap by conducting a simultaneous analysis of multiple asset classes over the same time horizon, focusing on inflation-hedging opportunities available to Swiss investors. Given the rising interest and debate surrounding cryptocurrencies as potential inflation hedges due to their decentralized nature and limited supply (Bouri et al., 2017), we extend our analysis to include this emerging asset class. Cryptocurrencies have been likened to gold in their inflation-hedging potential. However, their high volatility and relatively short track record as an asset class make their effectiveness as inflation hedges a subject of ongoing debate. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68d95be",
   "metadata": {},
   "source": [
    "### 1.4. Asset Classes \n",
    "\n",
    "Based on the findings of Stephan Arnold and Benjamin R. Auer (2015) in their paper *\"What Do Scientists Know About Inflation Hedging?\"*, the following asset classes were selected for analysis.\n",
    "\n",
    "1. Stocks:\n",
    "The literature suggests that stocks have a limited capacity to hedge against inflation in the short term, as evidenced by a negative relationship with inflation rates. However, long-term studies indicate that equities can provide inflation protection over periods exceeding five years.\n",
    "\n",
    "2. Gold and Commodities:\n",
    "Gold has historically exhibited a strong positive relationship with inflation, making it a popular choice as a store of value during inflationary periods. Early studies highlight a co-integrated relationship between gold and inflation, but more recent research shows that this connection can vary depending on economic conditions.\n",
    "To broaden the analysis, the focus was extended from gold to commodities as a whole, assessing their inflation-hedging potential for Swiss investors.\n",
    "\n",
    "3. Fixed Income:\n",
    "Fixed-income securities are generally sensitive to inflation, as nominal bonds lose value during inflationary periods due to their fixed coupon payments. In contrast, inflation-linked bonds, such as U.S. Treasury Inflation-Protected Securities (TIPS), provide more direct inflation hedging, though their availability and liquidity may be limited.\n",
    "\n",
    "4. Real Estate:\n",
    "Real estate has historically been considered a partial hedge against inflation, with earlier studies supporting its inflation-hedging properties. However, more recent research suggests that the effectiveness of real estate as an inflation hedge can vary depending on property types and inflation regimes.\n",
    "For this study, a selection of major Swiss real estate companies, Swiss real estate funds, international real estate ETFs, European real estate companies, and other relevant Swiss real estate securities was included to provide a comprehensive overview of tradable real estate assets for Swiss investors.\n",
    "\n",
    "5. Cryptocurrency:\n",
    "Cryptocurrencies, such as Bitcoin, have gained attention as potential inflation hedges due to their limited supply and decentralized nature (Bouri et al., 2017). Proponents argue that cryptocurrencies share similarities with gold, particularly in terms of scarcity. However, empirical evidence on their effectiveness as inflation hedges remains inconclusive, as cryptocurrencies are highly volatile and have a relatively short history as an asset class (Cheema et al., 2020).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4678f92",
   "metadata": {},
   "source": [
    "The following code prepares the environment by importing necessary libraries and defining shared functions for data preparation and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0190d372",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.13.0)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/milenazanolari/Documents/Digital-Tools-for-Finance/.venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from itertools import chain, combinations\n",
    "from tabulate import tabulate as tab\n",
    "from PIL import Image, ImageDraw, ImageFont\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c5b0bf",
   "metadata": {},
   "source": [
    "### 1.5. Data Sources\n",
    "\n",
    "The **Consumer Price Index (CPI)** data was sourced from the **Swiss Federal Statistical Office**, covering the period from December 1982 to November 2024, with the base year set to December 2020 (CPI = 100). The inflation rate was calculated as the percentage change in CPI compared to the previous year. To avoid issues with zero inflation values, a small positive value (`0.000000001`) was assigned when needed, ensuring data integrity for analysis.\n",
    "\n",
    "**Yahoo Finance** was selected as the data source for asset returns due to its seamless integration with Python via the `yfinance` library, providing accurate historical data. The analysis used **adjusted closing prices** to account for dividends, stock splits, and other corporate actions. No currency conversion was applied, focusing on nominal and real returns in the Swiss context, with tickers listed in **Swiss Francs (CHF)** or major global currencies. Ticker selection was guided by ChatGPT to identify relevant, tradable assets for Swiss investors seeking inflation hedging, with the number of tickers reduced to meet computational limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05585dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STOCKS\n",
    "#Top 3 SMI Constituents by Market Capitalization\n",
    "smi = \"^SSMI\"\n",
    "roche = \"ROG.SW\"\n",
    "nestle = \"NESN.SW\"\n",
    "#Top 3 European Companies by Market Capitalization\n",
    "novo_nordisk = \"NVO\"\n",
    "lvmh = \"MC.PA\"\n",
    "sap = \"SAP\"\n",
    "#Top 3 S&P 500 Constituents by Market Capitalization\n",
    "sp500 = \"^GSPC\"\n",
    "apple = \"AAPL\"\n",
    "nvidia = \"NVDA\"\n",
    "#Top 3 Asian Companies by Market Capitalization\n",
    "tsmc = \"TSM\"\n",
    "tencent = \"TCEHY\"\n",
    "\n",
    "#COMMODITIES\n",
    "# Broad Commodity ETFs\n",
    "invesco_commodity_composite_ucits_etf = \"LGCF.L\"\n",
    "# Gold ETFs\n",
    "ishares_physical_gold_etf = \"IGLN.L\"\n",
    "# Energy ETFs\n",
    "wisdomtree_brent_crude_oil = \"BRNT.L\"\n",
    "# Agriculture ETFs\n",
    "# Silver ETFs\n",
    "ishares_physical_silver_etf = \"ISLN.L\"\n",
    "# Specific Commodity ETFs\n",
    "wisdomtree_natural_gas = \"NGAS.L\"\n",
    "wisdomtree_wheat = \"WEAT.L\"\n",
    "wisdomtree_corn = \"CORN.L\"\n",
    "wisdomtree_soybeans = \"SOYB.L\"\n",
    "# Leveraged and Inverse Commodity ETFs\n",
    "# Commodity Equity ETFs\n",
    "# Commodity Futures ETFs\n",
    "# Commodity Currency-Hedged ETFs\n",
    "\n",
    "#FIXED INCOME SECURITIES\n",
    "# Broad Market Bond ETFs\n",
    "ishares_global_corporate_bond_ucits_etf = \"CORP.L\"\n",
    "# Government Bond ETFs\n",
    "ishares_us_treasury_bond_7_10yr_ucits_etf = \"IBTM.L\"\n",
    "# Corporate Bond ETFs\n",
    "ishares_usd_corporate_bond_ucits_etf = \"LQDE.L\"\n",
    "# High Yield Bond ETFs\n",
    "ishares_euro_high_yield_corporate_bond_ucits_etf = \"IHYG.L\"\n",
    "# Inflation-Linked Bond ETFs\n",
    "ishares_euro_inflation_linked_govt_bond_ucits_etf = \"IBCI.L\"\n",
    "ubs_etf_us_tips_ucits_etf = \"TIPS.L\"\n",
    "# Short Duration Bond ETFs\n",
    "ishares_euro_ultrashort_bond_ucits_etf = \"ERNE.L\"\n",
    "# Emerging Markets Bond ETFs\n",
    "ishares_jp_morgan_em_local_govt_bond_ucits_etf = \"IEML.L\"\n",
    "# Corporate Bond ETFs by Maturity\n",
    "# Aggregate Bond ETFs\n",
    "\n",
    "#REAL ESTATE\n",
    "# Swiss Real Estate Companies\n",
    "swiss_prime_site = \"SPSN.SW\"\n",
    "psp_swiss_property = \"PSPN.SW\"\n",
    "allreal_holding = \"ALLN.SW\"\n",
    "mobimo_holding = \"MOBN.SW\"\n",
    "# Swiss Real Estate Funds\n",
    "ubs_etf_sxi_real_estate = \"SRECHA.SW\"\n",
    "procimmo_swiss_commercial_fund = \"PSCF.SW\"\n",
    "# International Real Estate ETFs\n",
    "ishares_us_real_estate_etf = \"IYR\"\n",
    "ishares_global_reit_etf = \"REET\"\n",
    "\n",
    "#CRYPTOCURRENCY\n",
    "btc = \"BTC-USD\"\n",
    "eth = \"ETH-USD\"\n",
    "bnb = \"BNB-USD\"\n",
    "xrp = \"XRP-USD\"\n",
    "ada = \"ADA-USD\"\n",
    "\n",
    "asset_class_map = {\n",
    "  \"stocks\": [\n",
    "        \"^SSMI\", \"ROG.SW\", \"NESN.SW\", \n",
    "        \"NVO\", \"MC.PA\", \"SAP\", \n",
    "        \"^GSPC\", \"AAPL\", \"NVDA\", \n",
    "        \"TSM\", \"TCEHY\"\n",
    "    ],\n",
    "    \"commodities\": [\n",
    "        \"LGCF.L\", \"IGLN.L\", \"BRNT.L\", \n",
    "        \"ISLN.L\", \"NGAS.L\", \"WEAT.L\", \"CORN.L\", \n",
    "        \"SOYB.L\"\n",
    "    ],\n",
    "    \"fixed_income\": [\n",
    "        \"CORP.L\", \"IBTM.L\", \"LQDE.L\", \n",
    "        \"IHYG.L\", \"IBCI.L\", \"TIPS.L\", \n",
    "        \"ERNE.L\", \"IEML.L\"\n",
    "    ],\n",
    "    \"real_estate\": [\n",
    "        \"SPSN.SW\", \"PSPN.SW\", \"ALLN.SW\", \"MOBN.SW\", \n",
    "        \"SRECHA.SW\", \"PSCF.SW\", \"IYR\", \"REET\"\n",
    "    ],\n",
    "    \"cryptocurrency\": [\n",
    "        \"BTC-USD\", \"ETH-USD\", \"BNB-USD\", \"XRP-USD\", \"ADA-USD\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "#INTERVALS\n",
    "monthyl =\"1mo\"\n",
    "quarterly = \"3mo\"\n",
    "\n",
    "#TIME HORIZON\n",
    "one_year = \"1y\"\n",
    "two_year = \"2y\"\n",
    "five_year = \"5y\"\n",
    "ten_year = \"10y\"\n",
    "max_year = \"max\"\n",
    "\n",
    "#set file location\n",
    "script_dir = os.path.dirname(os.path.abspath(__file__))  # Location of the script\n",
    "project_root = os.path.abspath(os.path.join(script_dir, '..'))  # One level up from the script's directory\n",
    "dataset_path = os.path.join(project_root, 'Datasets', 'inflation_ch.csv') # Construct the path to the dataset\n",
    "tempfile_path = os.path.join(\n",
    "    project_root, 'Datasets') # Construct the path to the dataset\n",
    "\n",
    "# Check if the file already exists and create a unique filename\n",
    "counter = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd44d2c-4ff2-449a-9763-7d830d229224",
   "metadata": {},
   "source": [
    "#### Compute a list of assets\n",
    "- Input: *x syntax allows the function to accept any number of arguments\n",
    "- Process: converts the arguments into a list using list(x)\n",
    "- Output: returns the list of assets and prints a confirmation message with the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c83c61e9-9aaa-4931-861f-db15be582552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make(*x):\n",
    "    portfolio_assets = list(x)  # Create a list from the input arguments\n",
    "    print(f\"Created portfolio with assets: {portfolio_assets}\")\n",
    "    return portfolio_assets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9badffc5-cbf3-4708-a637-e31c74d93c0e",
   "metadata": {},
   "source": [
    "#### Calculate the average Year-over-Year (YoY) and Month-over-Month (MoM) returns across multiple assets.\n",
    "\n",
    "The `calculate_average_returns` function computes the average Year-over-Year (YoY) and Month-over-Month (MoM) returns for a set of assets. It takes a dictionary of DataFrames, with each DataFrame representing the data for a specific asset. The function processes the data to calculate the average returns over a specified interval and period.\n",
    "\n",
    "##### Parameters:\n",
    "- **`data_dict`**: A dictionary where each key is the asset name and the value is a DataFrame containing the asset's return data.\n",
    "- **`interval`**: A string that specifies the time interval (e.g., 'monthly', 'quarterly') used to calculate the returns.\n",
    "- **`period`**: A string representing the period for which returns are calculated (e.g., '1_year', '6_months').\n",
    "\n",
    "##### Process:\n",
    "1. **Input Validation**: The function ensures that the required YoY and MoM columns (dynamically named, e.g., AAPL_monthly_12m_YoY) exist in the DataFrame for each asset.\n",
    "2. **Concatenation**: It collects the relevant YoY and MoM columns for each asset, concatenates them into separate DataFrames, and calculates the row-wise average for both YoY and MoM returns.\n",
    "3. **Output**: The function returns a new DataFrame containing the average YoY and MoM returns across all assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5eb3aac1-7cb1-4940-b927-9aee3615d5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_returns(data_dict, interval, period):\n",
    "    # Initialize empty lists to store YoY and MoM DataFrames\n",
    "    yoy_dfs = []\n",
    "    mom_dfs = []\n",
    "\n",
    "    # Loop through each DataFrame in the dictionary\n",
    "    for asset, df in data_dict.items():\n",
    "        # Find the dynamically named YoY and MoM columns\n",
    "        yoy_column = f'{asset}_{interval}_{period}_YoY'\n",
    "        mom_column = f'{asset}_{interval}_{period}_MoM'\n",
    "        # Ensure the columns exist before appending\n",
    "        if yoy_column not in df.columns or mom_column not in df.columns:\n",
    "            raise ValueError(f\"DataFrame for '{asset}' is missing required columns: {yoy_column} or {mom_column}.\")\n",
    "\n",
    "        # Add the relevant columns to the lists\n",
    "        yoy_dfs.append(df[yoy_column])\n",
    "        mom_dfs.append(df[mom_column])\n",
    "\n",
    "    # Concatenate all YoY and MoM columns\n",
    "    yoy_combined = pd.concat(yoy_dfs, axis=1)\n",
    "    mom_combined = pd.concat(mom_dfs, axis=1)\n",
    "\n",
    "\n",
    "    # Calculate the averages across all columns (axis=1 means row-wise)\n",
    "    average_yoy = yoy_combined.mean(axis=1)\n",
    "    average_mom = mom_combined.mean(axis=1)\n",
    "\n",
    "    # Create a new DataFrame with the calculated averages\n",
    "    result_df = pd.DataFrame({\n",
    "        'average_YoY_return': average_yoy,\n",
    "        'average_MoM_return': average_mom\n",
    "    })\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b74f80-e7c0-479a-87e1-e60ced69802f",
   "metadata": {},
   "source": [
    "#### Generate a portfolio by extracting relevent data for the given stocks and calculating their average returns\n",
    "\n",
    "The `generate_portfolio` function allows you to create a portfolio by selecting specific assets from a data table based on a given interval and period. It extracts the necessary columns for each asset, calculates their returns using a custom `calculate_rates` function, and then computes the average returns for the selected assets using the `calculate_average_returns` function.\n",
    "\n",
    "##### Parameters:\n",
    "- **`*args`**: A variable number of asset name tickers (e.g., \"AAPL\", \"NVDA\"), representing the stocks or assets you want to include in the portfolio.\n",
    "- **`interval`**: A string indicating the time interval (e.g., 'monthly', 'quarterly') used for calculating the returns.\n",
    "- **`period`**: A string representing the period for which returns are calculated (e.g., '1_year', '6_months').\n",
    "- **`data_table`**: A DataFrame containing the asset data, where columns are dynamically named based on the asset name, interval, and period.\n",
    "\n",
    "##### Process:\n",
    "1. **Column Selection**: For each asset, the function dynamically generates the column name (e.g., \"monthly_12m\") based on the given interval (e.g., \"monthly\") and period (e.g., \"12m\"). It checks whether the corresponding column exists in the data table.\n",
    "2. **Data Extraction**: The relevant columns for each asset are extracted and stored in a dictionary.\n",
    "3. **Return Calculation**: The function applies the `calculate_rates` function to each asset's data to calculate the returns.\n",
    "4. **Average Calculation**: The `calculate_average_returns` function is called to compute the average Year-over-Year (YoY) and Month-over-Month (MoM) returns across all selected assets.\n",
    "5. **Output**: The function returns a DataFrame containing the average returns (YoY and MoM) for the portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75f40049-a580-4a9a-99a0-21337180daec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_portfolio(*args, interval, period, data_table):\n",
    "    column_suffix = f\"{interval}_{period}\"\n",
    "    selected_data = {}\n",
    "    # Extract relevant columns for each stock\n",
    "    for stock in args:\n",
    "        column_name = f\"{stock}_{column_suffix}\"\n",
    "        if column_name in data_table.columns:\n",
    "            selected_data[stock] = data_table[[column_name]]  # Select the specific column\n",
    "        else:\n",
    "            raise ValueError(f\"Column '{column_name}' not found in the provided data_table.\")\n",
    "    \n",
    "    # Apply the calculate_rates function to each DataFrame in the dictionary\n",
    "    calculated_data_dict = {key: calculate_rates(df) for key, df in selected_data.items()}\n",
    "    average_table = calculate_average_returns(calculated_data_dict, interval, period)\n",
    "\n",
    "\n",
    "    return average_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d723fce-317b-4ff4-bb9c-0d74d932563e",
   "metadata": {},
   "source": [
    "#### Retrieve financial data for multiple tickers over specified intervals and periods\n",
    "\n",
    "The `pull_data` function is used to download data for multiple tickers over different intervals and periods. It stores the data for each ticker in a dictionary and combines it into a single DataFrame for easy analysis.\n",
    "\n",
    "#### Parameters:\n",
    "- **`*tickers`**: A variable number of ticker symbols (e.g., 'APPL', 'NVDA'), representing the assets you want to pull data for.\n",
    "- **`intervals`**: A list of strings specifying the time intervals for which the data should be retrieved (e.g., 'monthly', 'quarterly').\n",
    "- **`periods`**: A list of strings representing the periods for which the data is needed (e.g., '1_year', '6_months').\n",
    "\n",
    "#### Process:\n",
    "1. **Data Download**: The function loops through each ticker, interval, and period combination, dynamically generating a key (ticker_interval_period) to store the corresponding data.\n",
    "2. **Data Retrieval**: Loop through tickers, intervals, and periods: Iterate over tickers (first argument), then for each ticker, iterate through the combinations of intervals and periods, create a unique key (`f\"{ticker}_{interval}_{period}\"`), and download the corresponding data using `download_ticker_data(ticker, interval, period)`, storing it in `data_dict` under the constructed key.\n",
    "3. **Data Combination**: After collecting all the data, the function combines it into a single DataFrame using `pd.concat()`, aligning the data by date.\n",
    "4. **Output**: The function returns the combined DataFrame containing all the downloaded data for the specified tickers, intervals, and periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6d9aaf5-6cc8-4af0-b274-b9126b7f8b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_data(*tickers, intervals, periods):\n",
    "    # Create a dictionary to store the data for each ticker\n",
    "    data_dict = {}\n",
    "        \n",
    "    # Loop through each ticker and download its data using download_ticker_data\n",
    "    for ticker in tickers[0]:\n",
    "        for interval in intervals:\n",
    "                for period in periods:\n",
    "                        key = f\"{ticker}_{interval}_{period}\"\n",
    "                        data_dict[key] = download_ticker_data(ticker, interval, period)\n",
    "    \n",
    "    # Combine all ticker data into a single DataFrame, aligning by date\n",
    "    combined_data = pd.concat(data_dict, axis=1)\n",
    "    #combined_data = pd.concat(data_dict.values(), axis=1, keys=data_dict.keys())\n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d285e0dd-6471-4014-b689-6f2035b82f2a",
   "metadata": {},
   "source": [
    "#### Fetch and process historical stock data for a specified ticker, interval, and period using the yfinance library.\n",
    "\n",
    "The `download_ticker_data` function downloads historical price data for a given asset using the **Yahoo Finance** API (`yfinance` library). It specifically retrieves the **adjusted close prices** for the asset, formats the data, and returns it in a structured DataFrame.\n",
    "\n",
    "#### Parameters:\n",
    "- **`ticker`**: The asset symbol (string) to fetch data for (e.g., 'AAPL', 'NVDA').\n",
    "- **`interval`**: The time interval for the data (e.g., '1d' for daily, '1wk' for weekly).\n",
    "- **`period`**: The time period over which to download data (e.g., '1y' for one year, '6mo' for six months).\n",
    "\n",
    "#### Process:\n",
    "1. **Download Data**: The function uses the `yf.download()` method to download the asset data for the specified ticker, interval, and period.\n",
    "2. **Select Adjusted Close**: It extracts only the adjusted closing prices from the downloaded data.\n",
    "3. **Reset Index**: The index (date) is reset to make the 'Date' a regular column.\n",
    "4. **Column Renaming**: The columns are renamed to match a standard format, with 'Date' and 'Value'.\n",
    "5. **Date Conversion**: The 'Date' column is converted to datetime format and set as the index, ensuring proper time series handling.\n",
    "6. **Timezone Handling**: The timezone information is removed from the index to avoid potential issues.\n",
    "7. **Sort by Date**: The data is sorted by date in ascending order to ensure the data is in chronological order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a37e5c1-7a57-4347-9a0e-4e955fb25f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_ticker_data(ticker, interval, period):\n",
    "        # Download maximum available data for the Gold\n",
    "        asset = yf.download(ticker, interval=interval, period=period)\n",
    "        asset_adj_close = asset[['Adj Close']]\n",
    "        # Reset the index to make 'Date' a regular column, if not already\n",
    "        asset_adj_close = asset_adj_close.reset_index()\n",
    "\n",
    "        # Rename columns to match the SMI format\n",
    "        asset_adj_close.columns = ['Date', 'Value']\n",
    "\n",
    "        # Convert 'Date' to datetime format and set as index (if not already a datetime type)\n",
    "        asset_adj_close['Date'] = pd.to_datetime(asset_adj_close['Date'], errors='coerce')\n",
    "        asset_adj_close.set_index('Date', inplace=True)\n",
    "\n",
    "        asset_adj_close.index = asset_adj_close.index.tz_localize(None)\n",
    "\n",
    "        # Sort by date in ascending order\n",
    "        asset_adj_close = asset_adj_close.sort_index(ascending=True)\n",
    "        return asset_adj_close"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df10fb7-6383-41d1-9b6d-50e1ab31f214",
   "metadata": {},
   "source": [
    "#### Calculate the average Year-over-Year (YoY) and Month-over-Month (MoM) CPI rates\n",
    "\n",
    "The `calculate_rates` function calculates the **Year-over-Year (YoY)** and **Month-over-Month (MoM)** return rates for each asset in the DataFrame. These return rates are calculated based on the percentage change in the asset's value over a specified period (12 months for YoY and 1 month for MoM).\n",
    "\n",
    "#### Parameters:\n",
    "- **`df`**: A **DataFrame** containing the asset data, with a multi-level column structure where the first level represents the asset tickers (e.g., 'AAPL', 'GOOG') and the second level represents the asset data (e.g., 'Value').\n",
    "\n",
    "#### Process:\n",
    "1. **Loop Through Assets**: The function iterates through each unique asset (ticker) in the DataFrame.\n",
    "2. **Calculate YoY**: For each asset, the Year-over-Year (YoY) return is calculated using the percentage change (`pct_change()`) over 12 months (i.e., 12 periods).\n",
    "3. **Calculate MoM**: The Month-over-Month (MoM) return is calculated using the percentage change over 1 month (i.e., 1 period).\n",
    "4. **Flatten Column Names**: After calculating the return rates, the function flattens the multi-level column names by keeping only the first level (asset tickers), if desired.\n",
    "5. **Return Data**: The function returns the modified DataFrame with the new columns for YoY and MoM returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf6a9b6c-d982-4878-ab5c-8d946fc2b839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rates(df):\n",
    "    # Loop through each asset column (ticker name only)\n",
    "    for column in df.columns.get_level_values(0).unique():\n",
    "        # Calculate Year-over-Year (YoY) return rate\n",
    "        df[f'{column}_YoY'] = df[(column, 'Value')].pct_change(12) * 100  # 12-month (YoY) change\n",
    "            \n",
    "        # Calculate Month-over-Month (MoM) return rate\n",
    "        df[f'{column}_MoM'] = df[(column, 'Value')].pct_change() * 100  # 1-month (MoM) change\n",
    "\n",
    "    # Drop the second level in column names (if desired) after calculation\n",
    "    df.columns = [col[0] if isinstance(col, tuple) else col for col in df.columns]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b863018",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "Our methodology for observing asset class performance as inflation hedges focuses solely on the hedging capabilities (safety) of asset classes against inflation rather than their returns. Our interest lies in their ability to preserve purchasing power during inflationary periods, independent of their overall performance as investment vehicles. Our approach prioritizes interpretability and practical application for portfolio construction. The research was conducted in two primary steps: selecting an evaluation framework and applying calculation methods. Each framework (all possibilities, rolling window method, single-value method) employed three different calculation approaches: single-beta linear regression, correlation, and real return.\n",
    "\n",
    "### 1. Evaluation Frameworks for Analyzing the Data\n",
    "\n",
    "In the first step, we chose one of three frameworks to analyze the data:\n",
    "\n",
    "- **All Possibilities Method**: This framework generates all possible portfolios by exploring combinations of assets within each class. The combinations include portfolios with 1, 2, or more assets, with equal weights assigned for simplicity. This method allows flexibility in defining a minimum number of assets per portfolio. We selected this framework as our primary approach due to its sophistication and comprehensive scope, ensuring that at least 2 different asset tickers are included in each asset class. The interpretation of results is grounded in this framework.\n",
    "\n",
    "- **Rolling Window Method**: A 12-month rolling window is applied to dynamically evaluate portfolio performance over time, capturing temporal trends and variations.\n",
    "\n",
    "- **Single-Value Method**: This method calculates a single, static value for each metric over the entire period, providing a high-level assessment of performance.\n",
    "\n",
    "### 2. Calculation Methods \n",
    "\n",
    "- **Single-Beta Linear Regression**: Models the relationship between portfolio returns (dependent variable) and inflation (independent variable), with the regression coefficient indicating the sensitivity of returns to inflation.\n",
    "\n",
    "- **Correlation**: Measures the strength and direction of the linear relationship between inflation and portfolio returns, with a high correlation indicating that portfolio returns closely match inflation changes.\n",
    "\n",
    "- **Real Return**: Adjusts nominal returns for inflation, providing a clearer picture of the true growth in purchasing power. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290d3d90",
   "metadata": {},
   "source": [
    "### Single-Beta Linear Regression \n",
    "\n",
    "In this approach, we use regression analysis to calculate the beta coefficients, which represent the the strength of sensitivity between inflation (independent variable) and asset/portfolio returns (dependent variable). The `calculate_beta` function calculates the beta values of assets in a portfolio relative to inflation, using both MoM and YoY inflation rates. Beta measures the sensitivity of an asset’s returns to changes in inflation rates, where a significant positive coefficient close to 1 implies effective inflation hedging. \n",
    "\n",
    "#### Parameters:\n",
    "- **`portfolio`**: A DataFrame containing the asset data, including the returns for the portfolio assets (both MoM and YoY returns).\n",
    "- **`portfolio_name`**: A string representing the name of the portfolio (used for identification purposes).\n",
    "\n",
    "#### Process:\n",
    "1. **Load CPI Data**: The function loads the CPI data from a CSV file that contains inflation values.\n",
    "2. **Prepare the CPI Data**:\n",
    "    - Convert the 'Date' column to a datetime format and set it as the index.\n",
    "    - Sort the data by date in ascending order.\n",
    "    - Convert the 'Value' column (CPI values) to numeric format.\n",
    "    - Calculate the MoM and YoY inflation rates by taking percentage changes over 1 month and 12 months, respectively.\n",
    "3. **Align Portfolio and CPI Data**: The function determines the earliest start date and the latest end date between the portfolio and CPI data, ensuring the datasets cover the same time period. It then filters both the CPI and portfolio data to match this common date range.\n",
    "4. **Merge CPI Data with Asset Returns**: The function merges the CPI data with the portfolio’s MoM and YoY returns on the 'Date' column, creating two separate merged DataFrames: one for MoM returns and one for YoY returns.\n",
    "5. **Remove NaN and Infinite Values**: Any rows with missing or infinite values are dropped, as they would interfere with the calculation of the correlation (beta).\n",
    "6. **Calculate Beta Values**:\n",
    "    - The function calculates the beta for each asset by comparing its MoM and YoY returns with the corresponding CPI inflation rates (MoM and YoY, respectively). The beta is computed using the `calculate_single_beta` function (which is assumed to be defined elsewhere in the code).\n",
    "    - The beta values for each asset are stored in a list and returned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8bbb986-f664-494e-9990-562e2e50f7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_beta(portfolio, portfolio_name):\n",
    "    cpi_data = pd.read_csv(dataset_path)\n",
    "\n",
    "    #prepare dataset DATETIME and ORDER\n",
    "    # Convert the 'Date' column to datetime format\n",
    "    cpi_data['Date'] = pd.to_datetime(cpi_data['Date'], errors='coerce')\n",
    "    cpi_data.set_index('Date', inplace=True)\n",
    "    cpi_data = cpi_data.sort_index(ascending=True)\n",
    "    cpi_data['Value'] = pd.to_numeric(cpi_data['Value'], errors='coerce')\n",
    "\n",
    "    #get RATES\n",
    "    cpi_data['Inflation_Rate_YoY'] = cpi_data['Value'].pct_change(12) * 100  # 12-month (YoY) change\n",
    "    cpi_data['Inflation_Rate_MoM'] = cpi_data['Value'].pct_change() * 100  # 1-month (MoM) change\n",
    "\n",
    "    #here we merge the dataset that same START and END point\n",
    "    # - merge that same START and END point\n",
    "\n",
    "    # Find the latest start date and earliest end date between the two datasets\n",
    "    start_date = max(cpi_data.index.min(), portfolio.index.min())\n",
    "    end_date = min(cpi_data.index.max(), portfolio.index.max())\n",
    "\n",
    "    # Filter both datasets to only include this date range\n",
    "    cpi_data = cpi_data[start_date:end_date]\n",
    "    portfolio = portfolio[start_date:end_date]\n",
    "\n",
    "    # Prepare to merge CPI with all assets' MoM and YoY rates\n",
    "    # Step 1: Merge CPI and assets data on Date for Month-over-Month Rates\n",
    "    merged_data_mom = pd.merge(\n",
    "        cpi_data[['Inflation_Rate_MoM']], \n",
    "        portfolio.filter(like='_MoM_return'),  # Select all MoM rate columns\n",
    "        left_index=True, \n",
    "        right_index=True\n",
    "    )\n",
    "\n",
    "    # Step 2: Merge CPI and assets data on Date for Year-over-Year Rates\n",
    "    merged_data_yoy = pd.merge(\n",
    "        cpi_data[['Inflation_Rate_YoY']], \n",
    "        portfolio.filter(like='YoY_return'),  # Select all YoY rate columns\n",
    "        left_index=True, \n",
    "        right_index=True\n",
    "    )\n",
    "\n",
    "    # Step 2: Drop any rows with NaN values, as these will interfere with correlation calculation\n",
    "    merged_data_mom.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    merged_data_mom.dropna(inplace=True)\n",
    "\n",
    "    merged_data_yoy.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    merged_data_yoy.dropna(inplace=True)\n",
    "\n",
    "    beta_values = []\n",
    "\n",
    "    for column in merged_data_mom.columns:\n",
    "        if column != 'Inflation_Rate_MoM':  # Skip the CPI column itself\n",
    "            beta = calculate_single_beta(\n",
    "                merged_data_mom['Inflation_Rate_MoM'],  # Independent variable (Inflation)\n",
    "                merged_data_mom[column]                # Dependent variable (Asset returns)\n",
    "            )\n",
    "            #print(f\"Beta value for {column}: {beta}\")\n",
    "            beta_values.append(beta)\n",
    "\n",
    "    for column in merged_data_yoy.columns:\n",
    "        if column != 'Inflation_Rate_YoY':  # Skip the CPI column itself\n",
    "            beta = calculate_single_beta(\n",
    "                merged_data_yoy['Inflation_Rate_YoY'],  # Independent variable (Inflation)\n",
    "                merged_data_yoy[column]                # Dependent variable (Asset returns)\n",
    "            )\n",
    "            #print(f\"Beta value for {column}: {beta}\")\n",
    "            beta_values.append(beta)\n",
    "\n",
    "    return beta_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4878a670",
   "metadata": {},
   "source": [
    "### 2. Correlation Analysis\n",
    "\n",
    "Correlation measures the strength and direction of the linear relationship between two variables. In this context, it evaluates how closely inflation and portfolio returns move together. Ideally, we seek a correlation of 1, indicating that portfolio returns perfectly match inflation changes. A high positive correlation greater than 1, for instance, would imply an overreaction of portfolio returns to inflation, which may not be desirable in times of deflation.\n",
    "\n",
    "The `calculate_correlation` function calculates the **correlation** between the **portfolio's asset returns** (both MoMh and YoY) and **inflation rates** (MoM and YoY). The function computes how the returns of assets in the portfolio are related to the CPI inflation data, providing a measure of the sensitivity of each asset's returns to inflation.\n",
    "\n",
    "#### Parameters:\n",
    "- **`portfolio`**: A DataFrame containing the portfolio's asset data, including return rates for the portfolio assets (both MoM and YoY).\n",
    "- **`portfolio_name`**: A string representing the name of the portfolio (used for identification purposes).\n",
    "\n",
    "#### Process (Code is different than the code for regression only in the last part -> after correlation_values = [].):\n",
    "1. **Load CPI Data**: The function loads the CPI data from a CSV file that contains inflation values.\n",
    "2. **Prepare the CPI Data**:\n",
    "    - Convert the 'Date' column to a datetime format and set it as the index.\n",
    "    - Sort the data by date in ascending order.\n",
    "    - Convert the 'Value' column (CPI values) to numeric format.\n",
    "    - Calculate the MoM and YoY inflation rates by taking percentage changes over 1 month and 12 months, respectively.\n",
    "3. **Align Portfolio and CPI Data**: The function determines the earliest start date and the latest end date between the portfolio and CPI data, ensuring the datasets cover the same time period. It then filters both the CPI and portfolio data to match this common date range.\n",
    "4. **Merge CPI Data with Asset Returns**: The function merges the CPI data with the portfolio’s MoM and YoY returns on the 'Date' column, creating two separate merged DataFrames: one for MoM returns and one for YoY returns.\n",
    "5. **Remove NaN and Infinite Values**: Any rows with missing or infinite values are dropped, as they would interfere with the calculation of the correlation (beta).\n",
    "6. **Calculate Correlations**:\n",
    "    - The function calculates the correlation coefficient for each asset in the portfolio with the CPI inflation rates (MoM and YoY).\n",
    "    - The correlation is calculated using the `.corr()` function in pandas, which measures the linear relationship between two variables.\n",
    "7. **Return Correlation Values**: The function returns a list of correlation values, each representing the relationship between an asset's return and the inflation rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d13ea255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_correlation(portfolio, portfolio_name):\n",
    "    #read dataset\n",
    "    # Replace 'path_to_cpi_data.csv' with the actual path to your CPI CSV file\n",
    "    cpi_data = pd.read_csv(dataset_path)\n",
    "\n",
    "    #prepare dataset DATETIME and ORDER\n",
    "    # Convert the 'Date' column to datetime format\n",
    "    cpi_data['Date'] = pd.to_datetime(cpi_data['Date'], errors='coerce')\n",
    "    cpi_data.set_index('Date', inplace=True)\n",
    "    cpi_data = cpi_data.sort_index(ascending=True)\n",
    "    cpi_data['Value'] = pd.to_numeric(cpi_data['Value'], errors='coerce')\n",
    "\n",
    "    #get RATES\n",
    "    cpi_data['Inflation_Rate_YoY'] = cpi_data['Value'].pct_change(12) * 100  # 12-month (YoY) change\n",
    "    cpi_data['Inflation_Rate_MoM'] = cpi_data['Value'].pct_change() * 100  # 1-month (MoM) change\n",
    "\n",
    "    #here we merge the dataset that same START and END point\n",
    "    # - merge that same START and END point\n",
    "\n",
    "    # Find the latest start date and earliest end date between the two datasets\n",
    "    start_date = max(cpi_data.index.min(), portfolio.index.min())\n",
    "    end_date = min(cpi_data.index.max(), portfolio.index.max())\n",
    "\n",
    "    # Filter both datasets to only include this date range\n",
    "    cpi_data = cpi_data[start_date:end_date]\n",
    "    portfolio = portfolio[start_date:end_date]\n",
    "\n",
    "    # Prepare to merge CPI with all assets' MoM and YoY rates\n",
    "    # Step 1: Merge CPI and assets data on Date for Month-over-Month Rates\n",
    "    merged_data_mom = pd.merge(\n",
    "        cpi_data[['Inflation_Rate_MoM']], \n",
    "        portfolio.filter(like='_MoM_return'),  # Select all MoM rate columns\n",
    "        left_index=True, \n",
    "        right_index=True\n",
    "    )\n",
    "\n",
    "    # Step 2: Merge CPI and assets data on Date for Year-over-Year Rates\n",
    "    merged_data_yoy = pd.merge(\n",
    "        cpi_data[['Inflation_Rate_YoY']], \n",
    "        portfolio.filter(like='YoY_return'),  # Select all YoY rate columns\n",
    "        left_index=True, \n",
    "        right_index=True\n",
    "    )\n",
    "\n",
    "    # Step 2: Drop any rows with NaN values, as these will interfere with correlation calculation\n",
    "    merged_data_mom.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    merged_data_mom.dropna(inplace=True)\n",
    "\n",
    "    merged_data_yoy.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    merged_data_yoy.dropna(inplace=True)\n",
    "\n",
    "    correlation_values = []\n",
    "\n",
    "    for column in merged_data_mom.columns:\n",
    "        if column != 'Inflation_Rate_MoM':  # Skip the CPI column itself\n",
    "            # Calculate correlation with CPI data for the entire dataset\n",
    "            correlation = merged_data_mom['Inflation_Rate_MoM'].corr(merged_data_mom[column])\n",
    "            correlation_values.append(correlation)\n",
    "\n",
    "\n",
    "    for column in merged_data_yoy.columns:\n",
    "        if column != 'Inflation_Rate_YoY':  # Skip the CPI column itself\n",
    "            # Calculate correlation with CPI data for the entire dataset\n",
    "            correlation = merged_data_yoy['Inflation_Rate_YoY'].corr(merged_data_yoy[column])\n",
    "            correlation_values.append(correlation)\n",
    "            \n",
    "\n",
    "    return correlation_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feefb57d",
   "metadata": {},
   "source": [
    "### 3. Real Return Analysis\n",
    "\n",
    "The `calculate_beta` function calculates the real return of assets in a portfolio after adjusting for inflation, providing a clearer picture of the true growth in purchasing power. It uses MoM and YoY inflation rates from CPI data and adjusts the nominal returns of the assets accordingly to obtain the real return. The real return reflects the performance of the asset after considering the erosion of purchasing power due to inflation and therefore the true growth of asset values over time. Portfolios with consistently high real returns are considered effective hedges.\n",
    "\n",
    "#### Parameters:\n",
    "- **`portfolio`**: A DataFrame containing the portfolio’s asset data, with asset returns (both MoM and YoY) and dates.\n",
    "- **`portfolio_name`**: A string representing the name of the portfolio (used for identification purposes).\n",
    "\n",
    "#### Process (Code is different than the code for regression only in the last part -> after correlation_values = [].):\n",
    "1. **Load CPI Data**: The function loads the CPI data from a CSV file that contains inflation values.\n",
    "2. **Prepare the CPI Data**:\n",
    "    - Convert the 'Date' column to a datetime format and set it as the index.\n",
    "    - Sort the data by date in ascending order.\n",
    "    - Convert the 'Value' column (CPI values) to numeric format.\n",
    "    - Calculate the MoM and YoY inflation rates by taking percentage changes over 1 month and 12 months, respectively.\n",
    "3. **Align Portfolio and CPI Data**: The function determines the earliest start date and the latest end date between the portfolio and CPI data, ensuring the datasets cover the same time period. It then filters both the CPI and portfolio data to match this common date range.\n",
    "4. **Merge CPI Data with Asset Returns**: The function merges the CPI data with the portfolio’s MoM and YoY returns on the 'Date' column, creating two separate merged DataFrames: one for MoM returns and one for YoY returns.\n",
    "5. **Remove NaN and Infinite Values**: Any rows with missing or infinite values are dropped, as they would interfere with the calculation of the correlation (beta).\n",
    "6. **Calculate Nominal and Real Returns**:\n",
    "    - Calculate real returns for MoM data by looping through the `merged_data_mom` DataFrame, which contains MoM returns for assets and CPI's MoM inflation rate, skipping the CPI column.\n",
    "    - Nominal return calculation: Convert percentage returns to decimals and calculate the compounded nominal return using `(1 + return)` and `.prod()`, then subtract 1.\n",
    "    - Replace zero inflation values and calculate the compounded inflation rate using the same formula as nominal returns to adjust for inflation.\n",
    "    - Adjust the nominal return for inflation by dividing the nominal growth factor by the inflation growth factor, then subtract 1 and multiply by 100 to get the percentage real return.\n",
    "    - Append the real return for each asset to the `real_return_values` list.\n",
    "    - Perform the same calculations for the `merged_data_yoy` DataFrame, which contains YoY returns and CPI's YoY inflation rate.\n",
    "7. **Return Real Return Values**: The function returns a list of real return values for each asset in the portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "682cd3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_beta(portfolio, portfolio_name):\n",
    "    #read dataset\n",
    "    # Replace 'path_to_cpi_data.csv' with the actual path to your CPI CSV file\n",
    "    cpi_data = pd.read_csv(dataset_path)\n",
    "\n",
    "    #prepare dataset DATETIME and ORDER\n",
    "    # Convert the 'Date' column to datetime format\n",
    "    cpi_data['Date'] = pd.to_datetime(cpi_data['Date'], errors='coerce')\n",
    "    cpi_data.set_index('Date', inplace=True)\n",
    "    cpi_data = cpi_data.sort_index(ascending=True)\n",
    "    cpi_data['Value'] = pd.to_numeric(cpi_data['Value'], errors='coerce')\n",
    "\n",
    "    #get RATES\n",
    "    cpi_data['Inflation_Rate_YoY'] = cpi_data['Value'].pct_change(12) * 100  # 12-month (YoY) change\n",
    "    cpi_data['Inflation_Rate_MoM'] = cpi_data['Value'].pct_change() * 100  # 1-month (MoM) change\n",
    "\n",
    "    #here we merge the dataset that same START and END point\n",
    "    # - merge that same START and END point\n",
    "\n",
    "    # Find the latest start date and earliest end date between the two datasets\n",
    "    start_date = max(cpi_data.index.min(), portfolio.index.min())\n",
    "    end_date = min(cpi_data.index.max(), portfolio.index.max())\n",
    "\n",
    "    # Filter both datasets to only include this date range\n",
    "    cpi_data = cpi_data[start_date:end_date]\n",
    "    portfolio = portfolio[start_date:end_date]\n",
    "\n",
    "    # Prepare to merge CPI with all assets' MoM and YoY rates\n",
    "    # Step 1: Merge CPI and assets data on Date for Month-over-Month Rates\n",
    "    merged_data_mom = pd.merge(\n",
    "        cpi_data[['Inflation_Rate_MoM']], \n",
    "        portfolio.filter(like='_MoM_return'),  # Select all MoM rate columns\n",
    "        left_index=True, \n",
    "        right_index=True\n",
    "    )\n",
    "\n",
    "    # Step 2: Merge CPI and assets data on Date for Year-over-Year Rates\n",
    "    merged_data_yoy = pd.merge(\n",
    "        cpi_data[['Inflation_Rate_YoY']], \n",
    "        portfolio.filter(like='YoY_return'),  # Select all YoY rate columns\n",
    "        left_index=True, \n",
    "        right_index=True\n",
    "    )\n",
    "\n",
    "    # Step 2: Drop any rows with NaN values, as these will interfere with correlation calculation\n",
    "    merged_data_mom.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    merged_data_mom.dropna(inplace=True)\n",
    "\n",
    "    merged_data_yoy.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    merged_data_yoy.dropna(inplace=True)\n",
    "\n",
    "    real_return_values = []\n",
    "\n",
    "    for column in merged_data_mom.columns:\n",
    "        if column != 'Inflation_Rate_MoM':  # Skip the CPI column itself\n",
    "            # Calculate nominal return\n",
    "            nominal_return = (1 + merged_data_mom[column] / 100).prod() - 1\n",
    "            #inflation_adjustment = (1 + merged_data_mom['Inflation_Rate_MoM'] / 100).prod() - 1\n",
    "            # Adjust for potential zero inflation rates during calculation\n",
    "            inflation_rates = merged_data_mom['Inflation_Rate_MoM'].replace(0, 1e-6)\n",
    "            inflation_adjustment = (1 + inflation_rates / 100).prod() - 1\n",
    "            real_return = ((1 + nominal_return) / (1 + inflation_adjustment) - 1) * 100\n",
    "\n",
    "            real_return_values.append(real_return)\n",
    "\n",
    "    for column in merged_data_yoy.columns:\n",
    "        if column != 'Inflation_Rate_YoY':  # Skip the CPI column itself\n",
    "            # Calculate nominal return\n",
    "            nominal_return = (1 + merged_data_yoy[column] / 100).prod() - 1\n",
    "            # Calculate inflation adjustment\n",
    "            inflation_adjustment = (1 + merged_data_yoy['Inflation_Rate_YoY'] / 100).prod() - 1\n",
    "            # Calculate single real return\n",
    "            real_return = ((1 + nominal_return) / (1 + inflation_adjustment) - 1) * 100\n",
    "            print(f\"Single YoY real return for {column} is {real_return:.4f}%\")\n",
    "            real_return_values.append(real_return)\n",
    "\n",
    "\n",
    "    return real_return_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68db55e4",
   "metadata": {},
   "source": [
    "### Advantages and Disadvantages of Different Calculation Methods\n",
    "\n",
    "Each of the used methods has its strengths and limitations:\n",
    "\n",
    "- **Single Beta** provides a quantitative measure of sensitivity to market movements and can handle multiple predictors. However, it assumes a linear relationship, which may not always hold in financial data.\n",
    "  \n",
    "- **Correlation** is simple to compute and interpret, offering a quick measure of co-movement between variables. However, it only shows statistical association without proving cause and effect, and it does not account for non-linear relationships.\n",
    "\n",
    "- **Real Return** directly reflects the actual financial outcome after adjusting for inflation, providing a clearer picture of performance. However, like other methods, it doesn't account for factors beyond inflation that may influence returns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3d375d",
   "metadata": {},
   "source": [
    "### Robustness Check Analysis\n",
    "\n",
    "The robustness check analysis encompasses three distinct perspectives to ensure the validity and reliability of our findings:\n",
    "- **Alternative Calculation Methodologies**: We employ multiple approaches to verify the consistency of results across different computational frameworks.\n",
    "- **Varied Time Horizons**: The analysis is conducted over multiple temporal ranges, including 2-year, 5-year, and 10-year periods, as well as the maximum available timeframe for each asset class, defined by the extent of historical data availability.\n",
    "- **Diverse Time Intervals**: We examine performance across different time aggregation intervals, specifically month-over-month (MoM) and year-over-year (YoY), to capture potential variations in temporal patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e255f6a",
   "metadata": {},
   "source": [
    "## Results, Interpretation and Visualisation (same for all three calculation methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60a5a2e",
   "metadata": {},
   "source": [
    "#### Generate all portfolios by combining asset classes, intervals, and time horizons\n",
    "The `make_all_portfolios` function generates portfolios by combining different asset classes, time horizons, and intervals. It groups the portfolios based on the specified intervals (e.g., monthly, quarterly), and for each combination of asset class and time horizon, it creates a portfolio. The resulting portfolios are stored in a dictionary, organized by interval.\n",
    "\n",
    "#### Parameters:\n",
    "- **`asset_classes`**: A list of asset classes (e.g., stocks, commodities), where each asset class is represented by a list of tickers.\n",
    "- **`intervals`**: A list of intervals (e.g., monthly, quarterly) to group portfolios by.\n",
    "- **`time_horizons`**: A list of time horizons (e.g., 2 years, 5 years, 10 years) to define the analysis period.\n",
    "- **`data_table`**: A DataFrame containing the asset data.\n",
    "\n",
    "#### Process:\n",
    "1. **Loop through Intervals**: The function iterates over each interval (e.g., monthly, quarterly) and initializes an empty dictionary to store portfolios for that interval.\n",
    "2. **Loop through Asset Classes**: For each asset class (e.g., stocks, commodities), it creates a name by joining the tickers in the asset class.\n",
    "3. **Loop through Time Horizons**: For each time horizon (e.g., 2 years, 5 years, 10 years), it generates a portfolio name based on the asset class, interval, and time horizon.\n",
    "4. **Generate Portfolios**: The function calls `generate_portfolio` to create the portfolio for the current combination of asset class, interval, and time horizon.\n",
    "5. **Store Portfolios**: Each generated portfolio is stored in the dictionary under the appropriate interval and portfolio name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20b6a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_portfolios(asset_classes, intervals, time_horizons, data_table):\n",
    "\n",
    "    all_portfolios_by_interval = {}\n",
    "\n",
    "    # Loop through intervals to group portfolios\n",
    "    for interval in intervals:\n",
    "        # Initialize a dictionary for portfolios under this interval\n",
    "        all_portfolios_by_interval[interval] = {}\n",
    "\n",
    "        for asset_class in asset_classes:\n",
    "            # Use the variable name (e.g., 'stocks', 'commodities') as the asset class name\n",
    "            #asset_class_name = [name for name in globals() if globals()[name] is asset_class][0]\n",
    "            asset_class_name = \"_\".join(asset_class)\n",
    "\n",
    "            for time_horizon in time_horizons:\n",
    "                # Generate a portfolio name\n",
    "                portfolio_name = f\"{asset_class_name}_{interval}_{time_horizon}\"\n",
    "\n",
    "                # Generate the portfolio for the current combination\n",
    "                demo_portfolio = generate_portfolio(*asset_class, interval=interval, period=time_horizon, data_table=data_table)\n",
    "\n",
    "                # Store the portfolio in the dictionary under the current interval\n",
    "                all_portfolios_by_interval[interval][portfolio_name] = demo_portfolio\n",
    "\n",
    "    return all_portfolios_by_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ef9067",
   "metadata": {},
   "source": [
    "#### Calculate correlations (e.g. beta) for all portfolios\n",
    "\n",
    "The `calculate_single_beta_for_all_portfolios` function calculates the beta values for all portfolios across different intervals. It iterates over the portfolios, calculating the beta for each one using the `calculate_beta` function and stores the results in a dictionary organized by interval.\n",
    "\n",
    "#### Parameters:\n",
    "- **`all_portfolios`**: A dictionary containing portfolios, grouped by intervals. Each portfolio includes asset return data, and the goal is to calculate the beta for each portfolio relative to inflation.\n",
    "\n",
    "#### Process:\n",
    "1. **Initialize Dictionary**: A dictionary `correlations_by_interval` is initialized to store the beta values for each portfolio, grouped by intervals.\n",
    "2. **Loop through Intervals**: The function iterates through each interval (e.g., monthly, quarterly).\n",
    "3. **Loop through Portfolios**: For each portfolio within the interval, it calculates the beta by calling the `calculate_beta` function.\n",
    "4. **Store Beta Values**: The resulting beta values are stored in the dictionary under the corresponding interval and portfolio name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2082415f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_single_beta_for_all_portfolios(all_portfolios):\n",
    "\n",
    "    # Initialize a dictionary to store the correlations\n",
    "    correlations_by_interval = {}\n",
    "\n",
    "    # Loop through intervals\n",
    "    for interval, portfolios in all_portfolios.items():\n",
    "        correlations_by_interval[interval] = {}\n",
    "        \n",
    "        # Loop through each portfolio\n",
    "        for portfolio_name, portfolio_data in portfolios.items():\n",
    "            # Calculate the correlation with CPI\n",
    "            correlation = calculate_beta(portfolio_data, portfolio_name)\n",
    "            \n",
    "            # Store the correlation result\n",
    "            correlations_by_interval[interval][portfolio_name] = correlation\n",
    "    return correlations_by_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a46e4b",
   "metadata": {},
   "source": [
    "#### Visualize MoM and YoY correlation data as tables\n",
    "\n",
    "The `plot_combined_correlation_table` function generates and displays two tables for each interval: one for the MoM correlation values and another for the YoY correlation values. These tables provide a visual representation of the relationship between portfolio returns and inflation, calculated through the beta values. The function creates tables for each interval (e.g., monthly, quarterly) and plots them side by side for comparison.\n",
    "\n",
    "#### Parameters:\n",
    "- **`correlations_dict`**: A dictionary containing correlation values for each portfolio, grouped by intervals. Each portfolio's key includes information about the asset class, interval, and time horizon.\n",
    "\n",
    "#### Process:\n",
    "1. **Initialize Lists**: Empty lists `mom_data` and `yoy_data` are initialized to store the correlation data for MoM and YoY, respectively.\n",
    "2. **Prepare Data for Each Interval**:\n",
    "    - The function loops through each interval (e.g., 'monthly', 'quarterly') and extracts the asset class and time horizon from the portfolio names.\n",
    "    - The MoM and YoY correlation values are added to the respective dictionaries.\n",
    "3. **Convert to DataFrames**: The correlation data is converted into DataFrames for both MoM and YoY using `pd.DataFrame.from_dict`.\n",
    "4. **Plotting**:\n",
    "    - Two tables are plotted side by side for each interval: one showing the MoM correlation values and the other showing the YoY correlation values.\n",
    "    - The tables are formatted to be clear and readable, with row labels for asset classes and column labels for time horizons.\n",
    "5. **Display**: The tables are displayed in a figure with subplots, where each row corresponds to a different interval, showing both MoM and YoY tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f346f13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined_correlation_table(correlations_dict):\n",
    "    # Initialize lists to organize data for the combined table\n",
    "    mom_data = []\n",
    "    yoy_data = []\n",
    "    intervals = []\n",
    "\n",
    "    # Prepare data for each interval\n",
    "    for interval, portfolios in correlations_dict.items():\n",
    "        table_data_mom = {}\n",
    "        table_data_yoy = {}\n",
    "\n",
    "        for portfolio_name, correlation_values in portfolios.items():\n",
    "            # Extract asset class and time horizon from the portfolio name\n",
    "            parts = portfolio_name.split('_')\n",
    "            asset_class = parts[0]\n",
    "            time_horizon = parts[-1]\n",
    "\n",
    "            # Add correlation values to respective dictionaries\n",
    "            if time_horizon not in table_data_mom:\n",
    "                table_data_mom[time_horizon] = {}\n",
    "                table_data_yoy[time_horizon] = {}\n",
    "            table_data_mom[time_horizon][asset_class] = round(correlation_values[0], 4)  # MoM Correlation\n",
    "            table_data_yoy[time_horizon][asset_class] = round(correlation_values[1], 4)  # YoY Correlation\n",
    "\n",
    "        # Convert to DataFrames\n",
    "        table_df_mom = pd.DataFrame.from_dict(table_data_mom, orient='index')\n",
    "        table_df_yoy = pd.DataFrame.from_dict(table_data_yoy, orient='index')\n",
    "\n",
    "        # Append interval data\n",
    "        mom_data.append((interval, table_df_mom))\n",
    "        yoy_data.append((interval, table_df_yoy))\n",
    "\n",
    "    # Plotting\n",
    "    fig, axes = plt.subplots(nrows=len(mom_data), ncols=2, figsize=(16, len(mom_data) * 5))\n",
    "    fig.suptitle(\"Single Beta Analysis\", fontsize=16)\n",
    "\n",
    "    # Loop through intervals for MoM and YoY\n",
    "    for i, (interval, mom_df) in enumerate(mom_data):\n",
    "        yoy_df = yoy_data[i][1]  # Corresponding YoY DataFrame\n",
    "\n",
    "        # Plot MoM table\n",
    "        ax_mom = axes[i, 0] if len(mom_data) > 1 else axes[0]  # Adjust for single row\n",
    "        ax_mom.axis('tight')\n",
    "        ax_mom.axis('off')\n",
    "        ax_mom.table(cellText=mom_df.values,\n",
    "                     rowLabels=mom_df.index,\n",
    "                     colLabels=mom_df.columns,\n",
    "                     cellLoc='center', loc='center')\n",
    "        ax_mom.set_title(\"MoM Single Beta\")\n",
    "\n",
    "        # Plot YoY table\n",
    "        ax_yoy = axes[i, 1] if len(mom_data) > 1 else axes[1]  # Adjust for single row\n",
    "        ax_yoy.axis('tight')\n",
    "        ax_yoy.axis('off')\n",
    "        ax_yoy.table(cellText=yoy_df.values,\n",
    "                     rowLabels=yoy_df.index,\n",
    "                     colLabels=yoy_df.columns,\n",
    "                     cellLoc='center', loc='center')\n",
    "        ax_yoy.set_title(\"YoY Single Beta\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.95)  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7bedd1",
   "metadata": {},
   "source": [
    "#### Summarize the structure of a nested dictionary by analyzing its contents\n",
    "\n",
    "The `summarize_dict` function provides a summary of a dictionary's contents, including information about the data types, lengths, and nested structures. It handles both regular dictionaries and nested dictionaries, giving insights into the structure of the data.\n",
    "\n",
    "#### Parameters:\n",
    "- **`data_dict`**: A dictionary to be summarized. It can contain other dictionaries as values (nested dictionaries), or non-dictionary values (e.g., lists, strings).\n",
    "\n",
    "#### Process:\n",
    "1. **Iterate through the dictionary**: The function loops through the key-value pairs in the dictionary.\n",
    "2. **Handle Nested Dictionaries**: If the value is a nested dictionary, the function counts the number of keys in the nested dictionary and summarizes its lengths.\n",
    "3. **Handle Non-Nested Dictionaries**: For values that are not dictionaries, the function captures the data type and, if the value has a length (e.g., list, string), it records the length.\n",
    "4. **Return Summary**: The function returns a summary dictionary containing:\n",
    "   - For regular values: the type of the value and its length (if applicable).\n",
    "   - For nested dictionaries: the number of keys and a breakdown of the lengths of the nested values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10d0ee6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_dict(data_dict):\n",
    "    summary = {}\n",
    "    for key, value in data_dict.items():\n",
    "        if isinstance(value, dict):  # If the value is a nested dictionary\n",
    "            nested_summary = {nested_key: len(nested_value) for nested_key, nested_value in value.items()}\n",
    "            summary[key] = {\n",
    "                \"type\": \"nested_dict\",\n",
    "                \"num_keys\": len(value),\n",
    "                \"lengths\": nested_summary\n",
    "            }\n",
    "        else:  # If it's not a nested dictionary\n",
    "            summary[key] = {\n",
    "                \"type\": type(value).__name__,\n",
    "                \"length\": len(value) if hasattr(value, '__len__') else None\n",
    "            }\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226d238b",
   "metadata": {},
   "source": [
    "#### Retrieve data for given assets, intervals, and time horizons\n",
    "\n",
    "The `make_data_table` function creates a data table by calling the `pull_data` function. It fetches asset data for the specified tickers, interval, and period, returning the data in a structured format for further analysis.\n",
    "\n",
    "#### Parameters:\n",
    "- **`*args`**: A variable number of ticker symbols (strings), representing the assets for which data is to be pulled.\n",
    "- **`interval`**: A string representing the time interval for the data (e.g., '1d' for daily, '1wk' for weekly).\n",
    "- **`period`**: A string representing the period for which the data is required (e.g., '1y' for one year, '6mo' for six months).\n",
    "\n",
    "#### Process:\n",
    "1. The function calls the `pull_data` function, passing the provided tickers, interval, and period.\n",
    "2. It returns the resulting data table, which contains the asset data for the specified tickers, interval, and period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aede3b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_table(*args, interval, period):\n",
    "\n",
    "    data_table = pull_data(args, intervals=interval, periods=period)\n",
    "    \n",
    "    return data_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9836c674",
   "metadata": {},
   "source": [
    "#### Group a list of assets into an asset classs\n",
    "\n",
    "The `make_asset_class` function creates an asset class by grouping the provided assets into an array. It takes a variable number of asset names (tickers) as input and returns a list containing all the assets.\n",
    "\n",
    "#### Parameters:\n",
    "- **`*assets`**: A variable number of asset names, representing the tickers of assets that will be included in the asset class.\n",
    "\n",
    "#### Process:\n",
    "1. The function initializes an empty list, `asset_array`.\n",
    "2. It then loops through each provided asset and appends it to the list.\n",
    "3. The function returns the populated list containing all the asset tickers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d942a030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_asset_class(*assets):\n",
    "\n",
    "    asset_array = []\n",
    "\n",
    "    for asset in assets:\n",
    "        asset_array.append(asset)\n",
    "    \n",
    "    return asset_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307fbc8f",
   "metadata": {},
   "source": [
    "#### Generate all subsets of an array with a minimum size\n",
    "\n",
    "The `find_subsets` function generates all possible subsets of a given array, with each subset having a size greater than or equal to a specified minimum size. It uses the `combinations` function from Python's `itertools` module to generate these subsets.\n",
    "\n",
    "#### Parameters:\n",
    "- **`array`**: A list or array of elements for which subsets are to be generated.\n",
    "- **`min_size`**: The minimum size of the subsets to generate (default is 1). If the minimum size is greater than the length of the array, a `ValueError` is raised.\n",
    "\n",
    "#### Process:\n",
    "1. The function checks if the `min_size` is valid (i.e., it cannot be greater than the length of the array).\n",
    "2. It uses the `combinations` function from the `itertools` module to generate subsets of all sizes greater than or equal to `min_size`.\n",
    "3. The function converts each subset into a list and returns a list of all subsets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c77fe1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_subsets(array, min_size=1):\n",
    "    if min_size > len(array):\n",
    "        raise ValueError(\"min_size cannot be greater than the number of elements in the array.\")\n",
    "    \n",
    "    # Generate all subsets of size >= min_size\n",
    "    subsets = chain.from_iterable(\n",
    "        combinations(array, r) for r in range(min_size, len(array) + 1)\n",
    "    )\n",
    "    subsets_as_lists = [list(subset) for subset in subsets]\n",
    "    return subsets_as_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7efffb",
   "metadata": {},
   "source": [
    "#### Generate all possible portfolios from subsets\n",
    "\n",
    "The `make_all_portfolios_per_asset_class` function generates portfolios by iterating over a list of subsets and appending each subset to a new list. This function is useful when creating portfolios for each asset class based on the subsets of assets.\n",
    "\n",
    "#### Parameters:\n",
    "- **`subsets`**: A list of subsets (lists of asset tickers) that represent potential combinations of assets within each asset class.\n",
    "\n",
    "#### Process:\n",
    "1. The function initializes an empty list, `all_portfolios`, to store the portfolios.\n",
    "2. It loops through each subset in the `subsets` list, appending each combination (subset) to the `all_portfolios` list.\n",
    "3. The function returns the list of all generated portfolios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11339c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_portfolios_per_asset_class(subsets):\n",
    "    all_portfolios = []\n",
    "    for combination in subsets:\n",
    "        all_portfolios.append(combination)\n",
    "    return all_portfolios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba263bd",
   "metadata": {},
   "source": [
    "#### Transform nested beta values into a flat DataFrame\n",
    "\n",
    "The `flatten_data` function transforms a nested dictionary of beta values into a structured Pandas DataFrame. This is done by flattening the nested dictionary into a list of dictionaries, where each dictionary contains details about the interval, portfolio name, and the corresponding MoM and YoY correlation values.\n",
    "\n",
    "#### Parameters:\n",
    "- **`beta_values`**: A dictionary containing beta values for portfolios, grouped by intervals. Each portfolio includes MoM and YoY correlation values.\n",
    "\n",
    "#### Process:\n",
    "1. The function initializes an empty list, `data`, to store the flattened data.\n",
    "2. It loops through each interval and portfolio, extracting the MoM and YoY correlation values.\n",
    "3. For each portfolio, a dictionary is created containing the interval, portfolio name, MoM correlation, and YoY correlation.\n",
    "4. The function returns a DataFrame created from the list of dictionaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da54e61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_data(beta_values):\n",
    "\n",
    "    data = []\n",
    "    for interval, portfolios in beta_values.items():\n",
    "        for portfolio_name, correlations in portfolios.items():\n",
    "            data.append({\n",
    "                \"Interval\": interval,\n",
    "                \"Portfolio\": portfolio_name,\n",
    "                \"MoM Correlation\": correlations[0],\n",
    "                \"YoY Correlation\": correlations[1]\n",
    "            })\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397fb306",
   "metadata": {},
   "source": [
    "#### Split flattened data into seperate MoM and YoY tables, then sort them\n",
    "\n",
    "The `split_and_sort` function splits a DataFrame into two separate tables: one for MoM correlations and one for YoY correlations. The function then sorts each table by the respective correlation values in descending order and resets the indices for cleaner presentation.\n",
    "\n",
    "#### Parameters:\n",
    "- **`dataframe`**: A Pandas DataFrame containing the data with columns for \"Interval\", \"Portfolio\", \"MoM Correlation\", and \"YoY Correlation\".\n",
    "\n",
    "#### Process:\n",
    "1. **Split the DataFrame**: The function separates the original DataFrame into two tables:\n",
    "   - One containing \"Interval\", \"Portfolio\", and \"MoM Correlation\" columns.\n",
    "   - One containing \"Interval\", \"Portfolio\", and \"YoY Correlation\" columns.\n",
    "2. **Sort the Tables**: Both tables are sorted by their respective correlation values (MoM or YoY) in descending order.\n",
    "3. **Reset Indices**: The indices of both tables are reset for cleaner output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "de8b1122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_sort(dataframe):\n",
    "\n",
    "    # Split into MoM and YoY tables\n",
    "    mom_table = dataframe[[\"Interval\", \"Portfolio\", \"MoM Correlation\"]].sort_values(by=\"MoM Correlation\", ascending=False)\n",
    "    yoy_table = dataframe[[\"Interval\", \"Portfolio\", \"YoY Correlation\"]].sort_values(by=\"YoY Correlation\", ascending=False)\n",
    "\n",
    "    # Reset indices for cleaner tables\n",
    "    mom_table.reset_index(drop=True, inplace=True)\n",
    "    yoy_table.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return mom_table, yoy_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3587e55f",
   "metadata": {},
   "source": [
    "#### Perform beta analysis for all portfolio combinations\n",
    "\n",
    "The `calcualte_beta_for_all` function generates and processes portfolios for all asset class combinations. For each combination, it calculates beta values, flattens and sorts the data, and creates tables for both MoM and YoY correlations. The function returns a dictionary containing the processed tables for each asset class combination.\n",
    "\n",
    "#### Parameters:\n",
    "- **`all_combinations`**: A list of all possible asset class combinations. Each combination is a list of asset classes to generate portfolios for.\n",
    "\n",
    "#### Process:\n",
    "1. **Generate Portfolios**: The function uses `make_all_portfolios` to generate portfolios based on the asset class combinations, intervals, time horizons, and test data.\n",
    "2. **Calculate Beta**: It then calculates the beta values for all portfolios using the `calculate_single_beta_for_all_portfolios` function.\n",
    "3. **Flatten and Sort Data**: The beta values are flattened into a structured DataFrame using the `flatten_data` function, and the data is sorted into separate MoM and YoY tables using the `split_and_sort` function.\n",
    "4. **Store Tables**: The function stores the MoM and YoY tables in a dictionary with a title that represents the asset class combination.\n",
    "5. **Return Tables**: The function returns a dictionary of all tables for each asset class combination.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b150e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcualte_beta_for_all(all_combinations):\n",
    "\n",
    "    all_tables = {}\n",
    "    for all in all_combinations:\n",
    "        all_portfolios = make_all_portfolios(all, intervalls, time_horizon, test_table)\n",
    "        all_single_beta_values = calculate_single_beta_for_all_portfolios(all_portfolios)\n",
    "        flattened_data = flatten_data(all_single_beta_values)\n",
    "        mom_table, yoy_table = split_and_sort(flattened_data)\n",
    "        # Determine the title based on asset class combinations\n",
    "        title = \"_\".join([\"_\".join(combination) for combination in all])\n",
    "       \n",
    "        # Store the flattened and sorted tables in a dictionary with the title\n",
    "        all_tables[title] = {\n",
    "            #\"flattened_data\": flattened_data,\n",
    "            \"MoM_table\": mom_table,\n",
    "            \"YoY_table\": yoy_table\n",
    "        }\n",
    "    \n",
    "    return all_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865fe020",
   "metadata": {},
   "source": [
    "#### Remove the Interval column from data tables\n",
    "\n",
    "The `drop_interval_column` function removes the \"Interval\" column from all tables in a given dictionary. It loops through the dictionary of tables, and for each table, it drops the \"Interval\" column.\n",
    "\n",
    "#### Parameters:\n",
    "- **`data`**: A dictionary containing tables (Pandas DataFrames) as values, where each table includes an \"Interval\" column.\n",
    "\n",
    "#### Process:\n",
    "1. The function loops through the dictionary `data`, accessing each table.\n",
    "2. For each table, it drops the \"Interval\" column using the `drop` method of Pandas.\n",
    "3. The modified dictionary is returned with the \"Interval\" column removed from all tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c0d43a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_interval_column(data):\n",
    "    for key, tables in data.items():\n",
    "        for table_name in tables:\n",
    "            tables[table_name] = tables[table_name].drop(columns=[\"Interval\"])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57b5a99",
   "metadata": {},
   "source": [
    "#### Assign a key to an asset class based on a mapping\n",
    "\n",
    "The `classify_key` function classifies a given key (e.g., portfolio name) based on a predefined mapping of assets to asset classes. The function splits the key into components, compares them to the mapped assets, and returns the corresponding asset class.\n",
    "\n",
    "#### Parameters:\n",
    "- **`key`**: A string representing the key (e.g., portfolio name) to be classified.\n",
    "- **`asset_class_map`**: A dictionary where the keys are asset classes (e.g., 'stocks', 'commodities'), and the values are lists of assets (tickers) that belong to each class.\n",
    "\n",
    "#### Process:\n",
    "1. The function splits the input `key` into components using the underscore (`_`) as a delimiter.\n",
    "2. It iterates over the `asset_class_map`, checking if any component of the key matches an asset in each asset class.\n",
    "3. If a match is found, the function returns the corresponding asset class.\n",
    "4. If no match is found, the function returns the default value `\"unknown\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f9bc62c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_key(key, asset_class_map):\n",
    "    components = key.split(\"_\")\n",
    "    \n",
    "    for asset_class, assets in asset_class_map.items():\n",
    "        if any(component in assets for component in components):\n",
    "            return asset_class \n",
    "    \n",
    "    return \"unknown\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d21ed2",
   "metadata": {},
   "source": [
    "#### Reorganize data into broader asset classes\n",
    "\n",
    "The `reclassify_titles_cleaned` function reclassifies data based on asset class mappings and consolidates the MoM and YoY tables for each asset class. It first classifies the keys (portfolio names) into asset classes, then organizes and combines the MoM and YoY tables accordingly.\n",
    "\n",
    "#### Parameters:\n",
    "- **`data`**: A dictionary where each key represents a portfolio name, and the values are dictionaries containing MoM and YoY tables.\n",
    "- **`asset_class_map`**: A dictionary mapping asset classes (e.g., 'stocks', 'commodities') to lists of assets (tickers).\n",
    "\n",
    "#### Process:\n",
    "1. **Classify Keys**: The function classifies each portfolio (key) using the `classify_key` function to determine the asset class.\n",
    "2. **Organize Data**: It checks if the asset class exists in the result dictionary (`reclassified_data`). If not, it initializes a new entry. The MoM and YoY tables are then appended to the corresponding asset class.\n",
    "3. **Concatenate Tables**: Once the tables are collected for each asset class, the function optionally concatenates the MoM and YoY tables for each asset class into single DataFrames.\n",
    "4. **Return Data**: The function returns the reclassified data with consolidated tables for each asset class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2de9566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reclassify_titles_cleaned(data, asset_class_map):\n",
    "    reclassified_data = {}\n",
    "    for key, value in data.items():\n",
    "        # Classify the key\n",
    "        asset_class = classify_key(key, asset_class_map)\n",
    "        \n",
    "        # If the asset class is not in the result, initialize it\n",
    "        if asset_class not in reclassified_data:\n",
    "            reclassified_data[asset_class] = {\"MoM_table\": [], \"YoY_table\": []}\n",
    "        \n",
    "        # Append the MoM_table and YoY_table directly to the asset class\n",
    "        if \"MoM_table\" in value:\n",
    "            reclassified_data[asset_class][\"MoM_table\"].append(value[\"MoM_table\"])\n",
    "        if \"YoY_table\" in value:\n",
    "            reclassified_data[asset_class][\"YoY_table\"].append(value[\"YoY_table\"])\n",
    "    \n",
    "    # Optionally, concatenate tables for each asset class\n",
    "    for asset_class, tables in reclassified_data.items():\n",
    "        if tables[\"MoM_table\"]:\n",
    "            reclassified_data[asset_class][\"MoM_table\"] = pd.concat(tables[\"MoM_table\"], ignore_index=True)\n",
    "        else:\n",
    "            del reclassified_data[asset_class][\"MoM_table\"]\n",
    "        if tables[\"YoY_table\"]:\n",
    "            reclassified_data[asset_class][\"YoY_table\"] = pd.concat(tables[\"YoY_table\"], ignore_index=True)\n",
    "        else:\n",
    "            del reclassified_data[asset_class][\"YoY_table\"]\n",
    "    \n",
    "    return reclassified_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aea1e23",
   "metadata": {},
   "source": [
    "#### Organize data by time horizons\n",
    "\n",
    "The `group_by_timestamp` function groups the data by the timestamp extracted from the Portfolio column. It processes the MoM and YoY tables for each asset class, extracts the timestamp from the portfolio name, and organizes the data by these timestamps for easy access and analysis.\n",
    "\n",
    "#### Parameters:\n",
    "- **`data`**: A dictionary containing asset classes as keys, with each asset class containing tables (MoM and YoY) as values. Each table is a Pandas DataFrame.\n",
    "\n",
    "#### Process:\n",
    "1. **Iterate Over Asset Classes**: The function loops through the asset classes (e.g., stocks, cryptocurrency) in the `data` dictionary.\n",
    "2. **Extract Timestamps**: It extracts the timestamp (e.g., '2y', 'max') from the Portfolio column using a regular expression (`r\"_(\\d+[y]|max)$\"`).\n",
    "3. **Group by Timestamp**: The data is grouped by the extracted timestamp, and each group is stored in a new dictionary structure.\n",
    "4. **Remove Timestamp Column**: The extracted Timestamp column is dropped for clarity, leaving only the grouped data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c603281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_timestamp(data):\n",
    "    grouped_data = {}\n",
    "    \n",
    "    # Iterate over the asset classes (e.g., stocks, cryptocurrency)\n",
    "    for asset_class, tables in data.items():\n",
    "        grouped_data[asset_class] = {}\n",
    "        \n",
    "        # Process each table (MoM_table and YoY_table)\n",
    "        for table_name, df in tables.items():\n",
    "            # Extract timestamp from Portfolio column\n",
    "            #df['Timestamp'] = df['Portfolio'].str.extract(r'_(\\d+[ymax]+)$')[0]\n",
    "            df[\"Timestamp\"] = df[\"Portfolio\"].str.extract(r\"_(\\d+[y]|max)$\")[0]\n",
    "\n",
    "            # Group by Timestamp and store in the new structure\n",
    "            for timestamp, group in df.groupby('Timestamp'):\n",
    "                if timestamp not in grouped_data[asset_class]:\n",
    "                    grouped_data[asset_class][timestamp] = {}\n",
    "                grouped_data[asset_class][timestamp][table_name] = group.drop(columns=['Timestamp'])\n",
    "    \n",
    "    return grouped_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709eb867",
   "metadata": {},
   "source": [
    "#### Identify portfolios with the highest and lowest correlations\n",
    "\n",
    "The `create_max_correlation_table` function creates a table that displays the portfolio with the highest correlation for each asset class and timeframe. The function searches through the given data and identifies the portfolio with the maximum correlation value for the specified table type (e.g., MoM or YoY).\n",
    "\n",
    "#### Parameters:\n",
    "- **`data`**: A dictionary containing asset classes as keys, with each asset class containing data for different timeframes (e.g., '2y', '5y', '10y', 'max'). Each timeframe contains tables (MoM or YoY) for which the maximum correlation needs to be identified.\n",
    "- **`table_type`**: A string specifying which type of table to search for (e.g., 'MoM_table' or 'YoY_table').\n",
    "\n",
    "#### Process:\n",
    "1. **Initialize Result Table**: The function initializes an empty Pandas DataFrame with timeframes ('2y', '5y', '10y', 'max') as rows and asset classes as columns.\n",
    "2. **Search for Maximum Correlation**: The function loops through each asset class and timeframe:\n",
    "   - If data exists for the specified timeframe and table type, it searches the corresponding table for the highest correlation value.\n",
    "   - It identifies the row with the maximum correlation and formats the result as \"Ticker: Value\".\n",
    "3. **Store Results**: The formatted results are stored in the `result_table` DataFrame.\n",
    "4. **Return Table**: The function returns the result_table containing the highest correlation values for each asset class and timeframe.\n",
    "\n",
    "Does the same for `create_min_correlation_table`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "282269da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_max_correlation_table(data, table_type):\n",
    "    timeframes = ['2y', '5y', '10y', 'max']\n",
    "    asset_classes = data.keys()\n",
    "    \n",
    "    # Initialize the results table\n",
    "    result_table = pd.DataFrame(index=timeframes, columns=asset_classes)\n",
    "    \n",
    "    # Fill the table\n",
    "    for asset_class in asset_classes:\n",
    "        for timeframe in timeframes:\n",
    "            # Check if the asset class has data for this timeframe and table type\n",
    "            if timeframe in data[asset_class] and table_type in data[asset_class][timeframe]:\n",
    "                # Get the table for the timeframe and type\n",
    "                df = data[asset_class][timeframe][table_type]\n",
    "                \n",
    "                # Find the row with the maximum correlation value\n",
    "                max_row = df.loc[df.iloc[:, 1].idxmax()]  # Assuming correlation is in the 2nd column\n",
    "                \n",
    "                # Format: \"Ticker: Value\"\n",
    "                result_table.loc[timeframe, asset_class] = f\"{max_row['Portfolio']}: {max_row.iloc[1]:.6f}\"\n",
    "    \n",
    "    return result_table\n",
    "\n",
    "def create_min_correlation_table(data, table_type):\n",
    "    timeframes = ['2y', '5y', '10y', 'max']\n",
    "    asset_classes = data.keys()\n",
    "    \n",
    "    # Initialize the results table\n",
    "    result_table = pd.DataFrame(index=timeframes, columns=asset_classes)\n",
    "    \n",
    "    # Fill the table\n",
    "    for asset_class in asset_classes:\n",
    "        for timeframe in timeframes:\n",
    "            # Check if the asset class has data for this timeframe and table type\n",
    "            if timeframe in data[asset_class] and table_type in data[asset_class][timeframe]:\n",
    "                # Get the table for the timeframe and type\n",
    "                df = data[asset_class][timeframe][table_type]\n",
    "                \n",
    "                # Find the row with the maximum correlation value\n",
    "                min_row = df.loc[df.iloc[:, 1].idxmin()]  # Assuming correlation is in the 2nd column\n",
    "                \n",
    "                # Format: \"Ticker: Value\"\n",
    "                result_table.loc[timeframe, asset_class] = f\"{min_row['Portfolio']}: {min_row.iloc[1]:.6f}\"\n",
    "    \n",
    "    return result_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cf243d",
   "metadata": {},
   "source": [
    "#### Render a pandas DataFrame as a figure\n",
    "\n",
    "The `display_table_as_figure` function displays a Pandas DataFrame as a table in a matplotlib figure. This function allows you to present a DataFrame visually with custom styling, including adjustable font size, column width, and a title.\n",
    "\n",
    "#### Parameters:\n",
    "- **`df`**: A Pandas DataFrame that you want to display as a table.\n",
    "- **`title`**: A string representing the title of the table to be displayed at the top of the figure.\n",
    "\n",
    "#### Process:\n",
    "1. **Create Figure**: The function creates a figure using matplotlib with a size adjusted based on the number of rows in the DataFrame.\n",
    "2. **Turn off Axis**: The axis is turned off to focus on the table, and the layout is set to 'tight' for better spacing.\n",
    "3. **Create Table**: The table is generated from the DataFrame, with options to center the text in each cell and display row and column labels.\n",
    "4. **Font and Column Width**: The font size is adjusted, and the column widths are auto-adjusted for a cleaner presentation.\n",
    "5. **Add Title**: A title is added to the table with custom font size and padding.\n",
    "6. **Display Table**: The table is displayed in the figure using `plt.show()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "834c8a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_table_as_figure(df, title):\n",
    "    fig, ax = plt.subplots(figsize=(10, len(df) * 0.6))  # Adjust height based on rows\n",
    "    ax.axis('off')  # Turn off the axis\n",
    "    ax.axis('tight')  # Tight layout for the table\n",
    "\n",
    "    # Create the table\n",
    "    table = ax.table(\n",
    "        cellText=df.values,\n",
    "        colLabels=df.columns,\n",
    "        rowLabels=df.index,\n",
    "        cellLoc=\"center\",\n",
    "        loc=\"center\"\n",
    "    )\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.auto_set_column_width(col=list(range(len(df.columns))))  # Auto-adjust column width\n",
    "\n",
    "    # Add title\n",
    "    plt.title(title, fontsize=14, pad=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5719a5f5",
   "metadata": {},
   "source": [
    "# Calculate Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9e6ed9",
   "metadata": {},
   "source": [
    "### Download Data\n",
    "\n",
    "In this step, we define the intervals and time horizons for the analysis which is part of our robustness analysis, and then download data for a variety of assets using the `make_data_table` function. The assets include stocks, commodities, fixed income, real estate, and cryptocurrencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d202d2fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'monthyl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m intervals \u001b[38;5;241m=\u001b[39m [\u001b[43mmonthyl\u001b[49m]\n\u001b[1;32m      2\u001b[0m time_horizon \u001b[38;5;241m=\u001b[39m [two_year, five_year, ten_year, max_year]    \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#Download all Data \u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#test_table = make_data_table(smi, sp500, world_etf, europe_etf, em_etf, gold, gold_etf, ch_gov_bond, tips_bond,treasury_etf, emerg_mark_bond, vang_real_est_etf, btc, eth, interval=intervals, period=time_horizon)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'monthyl' is not defined"
     ]
    }
   ],
   "source": [
    "intervals = [monthyl]\n",
    "time_horizon = [two_year, five_year, ten_year, max_year]    \n",
    "\n",
    "#Download all Data \n",
    "#test_table = make_data_table(smi, sp500, world_etf, europe_etf, em_etf, gold, gold_etf, ch_gov_bond, tips_bond,treasury_etf, emerg_mark_bond, vang_real_est_etf, btc, eth, interval=intervals, period=time_horizon)\n",
    "test_table = make_data_table(\n",
    "    smi, nestle, roche, novo_nordisk, lvmh, sap, sp500, apple,  \n",
    "    nvidia, tsmc, tencent,\n",
    "    invesco_commodity_composite_ucits_etf, ishares_physical_gold_etf, wisdomtree_brent_crude_oil, \n",
    "    ishares_physical_silver_etf, wisdomtree_natural_gas, wisdomtree_wheat, wisdomtree_corn, wisdomtree_soybeans, \n",
    "    ishares_global_corporate_bond_ucits_etf, ishares_usd_corporate_bond_ucits_etf, \n",
    "    ishares_euro_high_yield_corporate_bond_ucits_etf,\n",
    "    ishares_euro_inflation_linked_govt_bond_ucits_etf, ubs_etf_us_tips_ucits_etf, ishares_euro_ultrashort_bond_ucits_etf,\n",
    "    ishares_jp_morgan_em_local_govt_bond_ucits_etf, swiss_prime_site, psp_swiss_property, \n",
    "    allreal_holding, mobimo_holding, ubs_etf_sxi_real_estate, \n",
    "    procimmo_swiss_commercial_fund, ishares_us_treasury_bond_7_10yr_ucits_etf,\n",
    "    ishares_us_real_estate_etf, ishares_global_reit_etf, \n",
    "    btc, eth, bnb, xrp, ada, \n",
    "    interval=intervals, period=time_horizon\n",
    "    ) \n",
    "#Keep all possible portoflios of all asset classes here\n",
    "all_possible_portfolios_all_asset_classes = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f041df",
   "metadata": {},
   "source": [
    "\n",
    "### Portfolio Creation\n",
    "Create all possible portfolios for each asset class (stocks, commodities, fixed income, real estate, and cryptocurrency). \n",
    "\n",
    "For each asset class, we:\n",
    "1. Define the assets.\n",
    "2. Generate all possible combinations of these assets (portfolios with combinations of minimum 2 tickers).\n",
    "3. Add each portfolio to the `all_possible_portfolios_all_asset_classes` list for further analysis.\n",
    "\n",
    "\n",
    "The stock portfolio includes a variety of global stocks across different sectors.\n",
    "The commodities portfolio includes various ETFs and commodity indices. \n",
    "The fixed income portfolio includes a range of bond ETFs, including government, corporate, and inflation-linked bonds.\n",
    "The real estate portfolio includes Swiss and global real estate funds and ETFs. \n",
    "The cryptocurrency portfolio includes major cryptocurrencies such as Bitcoin and Ethereum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edc90d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------STOCKS-------------\n",
    "stocks = make_asset_class(\n",
    "    smi, nestle, roche, novo_nordisk, lvmh, sap,\n",
    "    apple, nvidia, tsmc, tencent\n",
    "    )\n",
    "\n",
    "stock_subset = find_subsets(stocks, 2)\n",
    "all_possible_portfolios_stocks = make_all_portfolios_per_asset_class(stock_subset)\n",
    "\n",
    "all_possible_portfolios_all_asset_classes.append(all_possible_portfolios_stocks)\n",
    "\n",
    "#------------COMMODITIES-------------\n",
    "commodities = make_asset_class(\n",
    "    invesco_commodity_composite_ucits_etf, ishares_physical_gold_etf, wisdomtree_brent_crude_oil,\n",
    "    ishares_physical_silver_etf, wisdomtree_natural_gas, wisdomtree_wheat, \n",
    "    wisdomtree_corn, wisdomtree_soybeans \n",
    "    )\n",
    "\n",
    "commodities_subset = find_subsets(commodities, 2)\n",
    "all_possible_portfolios_commodities = make_all_portfolios_per_asset_class(commodities_subset)\n",
    "\n",
    "all_possible_portfolios_all_asset_classes.append(all_possible_portfolios_commodities)\n",
    "\n",
    "#------------FIXED INCOME-------------\n",
    "fixed_income = make_asset_class(\n",
    "    ishares_global_corporate_bond_ucits_etf, ishares_us_treasury_bond_7_10yr_ucits_etf, \n",
    "    ishares_usd_corporate_bond_ucits_etf, ishares_euro_high_yield_corporate_bond_ucits_etf,\n",
    "    ishares_euro_inflation_linked_govt_bond_ucits_etf, ubs_etf_us_tips_ucits_etf, ishares_euro_ultrashort_bond_ucits_etf,\n",
    "    ishares_jp_morgan_em_local_govt_bond_ucits_etf\n",
    "    )\n",
    "\n",
    "fixed_income_subset = find_subsets(fixed_income, 2)\n",
    "all_possible_portfolios_fixed_income = make_all_portfolios_per_asset_class(fixed_income_subset)\n",
    "\n",
    "all_possible_portfolios_all_asset_classes.append(all_possible_portfolios_fixed_income)\n",
    "\n",
    "#------------REAL ESTATE-------------\n",
    "real_estate = make_asset_class(\n",
    "    swiss_prime_site, psp_swiss_property, allreal_holding, mobimo_holding, \n",
    "    ubs_etf_sxi_real_estate, procimmo_swiss_commercial_fund, ishares_us_real_estate_etf, ishares_global_reit_etf\n",
    "    )\n",
    "\n",
    "real_estate_subset = find_subsets(real_estate, 2)\n",
    "all_possible_portfolios_real_estate = make_all_portfolios_per_asset_class(real_estate_subset)\n",
    "\n",
    "all_possible_portfolios_all_asset_classes.append(all_possible_portfolios_real_estate)\n",
    "\n",
    "#------------CRYPTOCURRENCY------------\n",
    "crypto = make_asset_class(\n",
    "    btc, eth, bnb, xrp, ada \n",
    "    )\n",
    "\n",
    "crypto_subset = find_subsets(crypto, 2)\n",
    "all_possible_portfolios_crypto = make_all_portfolios_per_asset_class(crypto_subset)\n",
    "\n",
    "all_possible_portfolios_all_asset_classes.append(all_possible_portfolios_crypto)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf792f5",
   "metadata": {},
   "source": [
    "### Beta Calculation and Max/Min Correlation Tables\n",
    "\n",
    "In this step, we process the data to clean it, reclassify titles, and group it by timestamps. We then generate the maximum and minimum correlation tables for both MoM and YoY correlations.\n",
    "\n",
    "#### Parameters:\n",
    "- **`title`**\n",
    "- **`all_possible_portfolios_all_asset_classes`**: A list containing all asset class portfolios created in previous steps.\n",
    "- **`drop_interval_column`**: Function that takes in the beta data and removes the \"Interval\" column.\n",
    "- **`reclassify_titles_cleaned`**: A function that organizes portfolios into respective asset classes using an asset class map.\n",
    "- **`group_by_timestamp`**: A function that groups the data by different timestamps (e.g., 2 years, 5 years, 10 years) to enable correlation analysis.\n",
    "- **`create_max_correlation_table`**: Function that creates the maximum correlation tables for MoM and YoY correlations.\n",
    "- **`create_min_correlation_table`**: Function that creates the minimum correlation tables for MoM and YoY correlations.\n",
    "\n",
    "#### Process:\n",
    "1. **Calculate Beta**: Compute beta values for all portfolios using the `calculate_beta_for_all` function.\n",
    "2. **Clean Data**: Remove the \"Interval\" column from the dataset using the `drop_interval_column` function.\n",
    "3. **Reclassify Titles**: Organize portfolios into asset classes using the `reclassify_titles_cleaned` function, making the data more interpretable.\n",
    "4. **Group by Timestamp**: Group the data by time periods (2 years, 5 years, etc.) using the `group_by_timestamp` function.\n",
    "5. **Generate Maximum Correlation Tables**: Use `create_max_correlation_table` to create tables that highlight the portfolios with the highest MoM and YoY correlations.\n",
    "6. **Generate Minimum Correlation Tables**: Similarly, use `create_min_correlation_table` to identify the portfolios with the lowest MoM and YoY correlations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20915eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_returns = calculate_beta_for_all(all_possible_portfolios_all_asset_classes)\n",
    "\n",
    "#Clean up Data\n",
    "#drop interval\n",
    "all_returns_no_intervall = drop_interval_column(all_returns)\n",
    "#change titles\n",
    "reclassified_data = reclassify_titles_cleaned(all_returns_no_intervall, asset_class_map)\n",
    "print(reclassified_data)\n",
    "#group by timestamp\n",
    "grouped_data = group_by_timestamp(reclassified_data)\n",
    "\n",
    "# Generate the max MoM and YoY tables\n",
    "mom_table_max = create_max_correlation_table(grouped_data, 'MoM_table')\n",
    "yoy_table_max = create_max_correlation_table(grouped_data, 'YoY_table')\n",
    "\n",
    "# Generate the min MoM and YoY tables\n",
    "mom_table_min = create_min_correlation_table(grouped_data, 'MoM_table')\n",
    "yoy_table_min = create_min_correlation_table(grouped_data, 'YoY_table')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e0c128",
   "metadata": {},
   "source": [
    "### Visualization of Results: Color Code Tablesm and display tables as heatmaps\n",
    "\n",
    "Visualize the correlation tables using color scales and heatmaps. The goal is to highlight significant correlations and present the data in an easily interpretable format.\n",
    "\n",
    "The `color_scale_table` function applies a color scale to a DataFrame to visually differentiate values above and below a specified threshold (0.5 in this case). It highlights cells in green for values greater than 0.5 and red for values less than or equal to 0.5.\n",
    "\n",
    "**Parameters**:\n",
    "- **`df`**: A Pandas DataFrame that contains the data to be styled.\n",
    "\n",
    "**Process**:\n",
    "1. Convert all values in the DataFrame to floats, replacing non-numeric entries with NaN.\n",
    "2. Apply a color scale to each cell: green for values greater than 0.5 and red for values less than or equal to 0.5.\n",
    "\n",
    "The `display_heatmap` function creates a heatmap from a DataFrame using Seaborn. It visualizes the values as a color map, allowing to easily spot correlations. The heatmap uses a colormap (cmap), which is typically chosen from available color schemes like \"coolwarm\".\n",
    "\n",
    "**Parameters**:\n",
    "- **`df`**: A Pandas DataFrame that contains the data to be visualized.\n",
    "- **`title`**: A string representing the title of the heatmap.\n",
    "- **`cmap`**: The colormap to use for the heatmap (e.g., \"coolwarm\").\n",
    "\n",
    "**Process**:\n",
    "1. Convert all values to floats while handling non-numeric values as NaN.\n",
    "2. Drop rows and columns that contain only NaN values.\n",
    "3. Create and display a heatmap, adding the title and axis labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a000e2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_scale_table(df):\n",
    "    \"\"\"\n",
    "    Apply color scaling to a DataFrame.\n",
    "    Highlights cells in green for values > 0.5 and red for values <= 0.5.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to style.\n",
    "    \n",
    "    Returns:\n",
    "        pd.io.formats.style.Styler: A styled DataFrame with color formatting.\n",
    "    \"\"\"\n",
    "    # Ensure all numeric values are floats, replace non-numeric entries with NaN\n",
    "    def safe_float(x):\n",
    "        try:\n",
    "            return float(x)  # Convert to float if possible\n",
    "        except:\n",
    "            return np.nan  # Replace non-numeric values with NaN\n",
    "    \n",
    "    # Apply numeric conversion\n",
    "    df_numeric = df.applymap(safe_float)\n",
    "\n",
    "    # Define a helper function for individual cells\n",
    "    # Define a helper function for individual cells\n",
    "    def color_scale(val):\n",
    "        if pd.isna(val):  # Check for NaN\n",
    "            return ''  # No style for NaN\n",
    "        return 'background-color: green' if val > 0.5 else 'background-color: red'\n",
    "    \n",
    "    # Apply the color scale function element-wise to the DataFrame\n",
    "    return df_numeric.style.applymap(color_scale)\n",
    "\n",
    "def display_heatmap(df, title, cmap):\n",
    "    \"\"\"\n",
    "    Display a DataFrame as a heatmap.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to display.\n",
    "        title (str): The title for the heatmap.\n",
    "        cmap (str): The colormap to use (default: \"coolwarm\").\n",
    "    \"\"\"\n",
    "    # Convert all numeric values, handle non-numeric cells as NaN\n",
    "    # df = df.applymap(lambda x: round(float(x), 2) if isinstance(x, (int, float, np.number)) else x)\n",
    "\n",
    "    def safe_float(x):\n",
    "        try:\n",
    "            return round(float(x), 2)\n",
    "        except:\n",
    "            return np.nan  # Keep non-numeric values as is\n",
    "    \n",
    "    df = df.applymap(safe_float)\n",
    "    \n",
    "    # Drop rows and columns that are entirely NaN\n",
    "    df_numeric = df.dropna(how='all', axis=0)  # Drop rows with all NaNs\n",
    "    df_numeric = df_numeric.dropna(how='all', axis=1)  # Drop columns with all NaNs\n",
    "\n",
    "    # Check if the DataFrame is empty after cleaning\n",
    "    if df_numeric.empty:\n",
    "        print(\"The DataFrame is empty after cleaning. Cannot plot a heatmap.\")\n",
    "        return\n",
    "    \n",
    "    # Create the heatmap\n",
    "    plt.figure(figsize=(10, len(df) * 0.6))\n",
    "    sns.heatmap(df_numeric, annot=True, fmt=\".2f\", cmap=cmap, linewidths=0.5, cbar=True, \n",
    "                xticklabels=df.columns, yticklabels=df.index)\n",
    "\n",
    "    # Add title and labels\n",
    "    plt.title(title, fontsize=14, pad=20)\n",
    "    plt.xlabel(\"Asset Classes\")\n",
    "    plt.ylabel(\"Timeframes\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e112f49",
   "metadata": {},
   "source": [
    "### Final Results\n",
    "Display the generated correlation tables with and without color scaling for visual clarity. Use `display_table_with_tab` to show the tables in the terminal and `display_table_with_colorscale` to highlight the values with color scales.\n",
    "\n",
    "**Parameters**:\n",
    "- **`mom_table_max`**: The Maximum MoM Correlation Table to be displayed with a color scale.\n",
    "- **`yoy_table_max`**: The Maximum YoY Correlation Table to be displayed with a color scale.\n",
    "- **`mom_table_min`**: The Minimum MoM Correlation Table to be displayed with a color scale.\n",
    "- **`yoy_table_min`**: The Minimum YoY Correlation Table to be displayed with a color scale.\n",
    "\n",
    "\n",
    "**Process**:\n",
    "1. The `display_table_with_tab` function outputs the Maximum MoM Correlation Table in the terminal. This allows a quick and simple way to view the table's content without any color formatting.\n",
    "2. The `display_table_with_colorscale` function displays the tables with an applied color scale. Cells are highlighted based on the correlation values, providing a clear visual of which values are significant.\n",
    "    - Green is applied to values greater than 0.5.\n",
    "    - Red is used for values less than or equal to 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406f15f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_table_with_tab(mom_table_max, \"Maximum MoM Correlation Table\") # Displays in terminal\n",
    "\n",
    "\n",
    "display_table_with_colorscale(mom_table_max, \"Maximum MoM Correlation Table\")\n",
    "display_table_with_colorscale(yoy_table_max, \"Maximum YoY Correlation Table\")\n",
    "display_table_with_colorscale(mom_table_min, \"Minimum MoM Correlation Table\")\n",
    "display_table_with_colorscale(yoy_table_min, \"Minimum YoY Correlation Table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f142cec",
   "metadata": {},
   "source": [
    "## Comparison of Results\n",
    "After running all three methods, we summarize and compare the results to identify trends and insights across the approaches.\n",
    "It is important to highlight that our analysis prioritizes hedging capabilities—emphasizing safety and risk mitigation—rather than profit potential.\n",
    "\n",
    "First, we need to make clear which values of each calculation method are more favorable than the others.\n",
    "- Single-beta linear regression: beta measures the sensitivity of the asset's return to changes in inflation. A beta coefficient of 1 is ideal, indicating the asset's return increase proportionally with inflation.\n",
    "- Correlation: ideally, we would like to have an asset with correlation coefficient of 1. An asset with a correlation of +1 with inflation directly mirrors inflationary movements. This ensures that the asset's value grows at the same rate as inflation, preserving purchasing power perfectly.\n",
    "- Real return: we prefer assets with high real returns, because assets which maintain or grow their purchasing power during inflationary periods are better hedges. A consistently positive real return, especially during periods of high inflation, is ideal.\n",
    "\n",
    "Key Observations:\n",
    "- **Single-Beta Linear Regression**: Supports the theory that commodities, fixed income, and real estate are effective inflation hedges.\n",
    "- **Correlation-Based Approach**: Tends to emphasize volatile assets (e.g., cryptocurrencies, stocks).\n",
    "- **Real Returns**: Less intuitive for the context of inflation hedging.\n",
    "\n",
    "Based on our research, we focused on the single-beta linear regression methodology for hedging against inflation for Swiss investors, as it aligns closely with economic theories and provides more intuitive results than other methods.\n",
    "\n",
    "#### Short-Term Inflation Hedging (5-Year Horizon)\n",
    "\n",
    "- **MoM**: Commodities (IGLN.L and ISLN.L) are favorable.\n",
    "- **YoY**: Stocks (NESN.SW and NVO) and real estate (SPSN.SW and PSPN.SW) are effective.\n",
    "- **Strategy**: A mix of commodities, real estate, and stocks provides optimal short-term inflation protection.\n",
    "\n",
    "#### Medium-Term Inflation Hedging (10-Year Horizon)\n",
    "\n",
    "- **MoM**: Fixed income (TIPS.L and IEML.L) and real estate (IYR, REET).\n",
    "- **YoY**: Real estate (PSPN.SW and REET) and fixed income (ERNE.L and TEML.L).\n",
    "- **Strategy**: A diversified portfolio of real estate and fixed income assets is most effective for medium-term hedging.\n",
    "\n",
    "#### Long-Term Inflation Hedging (15+ Year Horizon)\n",
    "\n",
    "- **MoM and YoY**: Real estate consistently recommended (IYR, REET, PSPN.SW).\n",
    "- **Strategy**: Real estate is the optimal choice for long-term inflation protection.\n",
    "\n",
    "This analysis highlights asset classes and portfolios that are optimal for different time horizons.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c64ed4d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This study explores the inflation-hedging potential of various asset classes for Swiss investors, including equities, fixed income, real estate, commodities, and cryptocurrencies. Key findings include:\n",
    "- **Stocks**: Demonstrated uncertain effectiveness as inflation hedges, with correlation decreasing over longer horizons—an unfavorable trend—while beta from linear regression also declined, suggesting a potentially favorable but inconclusive relationship.\n",
    "- **Commodities**: Demonstrated robust hedging capabilities in short- to medium-term horizons, particularly in year-over-year analysis. They are a flexible and dynamic component of inflation-hedging strategies.\n",
    "- **Fixed Income**: Inflation-linked bonds provided moderate hedging effectiveness, especially in medium-term horizons. They offer a balanced approach between risk and return. \n",
    "- **Real Estate**: Consistently showed strong effectiveness as a long-term hedge against inflation. It is a stable and reliable option for inflation protection across multiple time horizons.\n",
    "- **Cryptocurrencies**: While showing high real returns during inflationary periods, cryptocurrencies exhibited high volatility and inconsistent correlation with inflation, making them less suitable for conservative inflation protection.\n",
    "\n",
    "Overall, the study highlights the importance of diversification across asset classes to achieve effective inflation protection while managing risk and return.\n",
    "\n",
    "#### Limitations:\n",
    "- **Computational Constraints**: The all-possibilities framework requires significant processing power and limits the number of assets that can be included.\n",
    "- **Historical Data Limitations**: The reliance on historical data affects comparability across asset classes.\n",
    "- **Assumptions**: The linear regression model assumes constant relationships, and the exclusion of currency effects may overlook important factors in globally diversified portfolios.\n",
    "\n",
    "#### Future Research:\n",
    "- **Advanced Models**: Employing techniques like nonlinear regression or machine learning could provide more accurate models for inflation-hedging.\n",
    "- **Inflation Decomposition**: Investigating expected and unexpected inflation components may provide deeper insights.\n",
    "- **Alternative Asset Classes**: Exploring other asset classes, like private equity or infrastructure, could uncover additional opportunities for hedging.\n",
    "- **Macroeconomic Factors**: Considering currency fluctuations, interest rates, and economic growth could enhance the understanding of inflation-hedging strategies.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
